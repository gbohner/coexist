{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 model for policy makers in the United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p align=\"center\">\n",
    " <img src=\"images/dynamicalModel.png\" width=\"70%\">\n",
    " </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an extended [SEIR model](https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#The_SEIR_model) to capture available information both about the disease progression, as well as how accessible various disease states are by testing. Being tested might cause a transition in the <span style=\"display: inline-block;background-color:#FFFCCC\">Testing State</span>; the rate of such a transition depends both on the <span style=\"display: inline-block;background-color:#D1E2FF\">Health State</span> as well the parameters of the test used.\n",
    "\n",
    "Due to age being both an extra risk factor as well as a potential way for decision makers to clearly apply policies to only parts of the total population, we include it directly in our model, and most transition rates are strongly influenced by <span style=\"display: inline-block;background-color:#FFD4D1\">Age State</span>.\n",
    "\n",
    "Finally, the main policy making tool as well as conundrum nowadays is the implementation of quarantining and social distancing in order to keep hospitals and medical staff under tolerable levels of pressure. We represent <span style=\"display: inline-block;background-color:#C2EDC0\">Isolation States</span> to investigate the effects of various interventions on policy targets relating to hospitalisation rates and economic freedom, while describing the different health outcomes via the <span style=\"display: inline-block;background-color:#D1E2FF\">Health States</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health states and Disease progression\n",
    "\n",
    "Susceptible people may be Exposed to the virus by mixing with other infected people (E,A,I<sub>1</sub> and I<sub>2</sub>).\n",
    "\n",
    "They may get through the infection Asymptomatic and eventually Recover, or become symptomatic and more Infectious, spreading the disease, and potentially Dying or Recovering.\n",
    "\n",
    "Recovered people develop more effective antibodies against the virus, and are considered immune<sup>*</sup>.\n",
    "\n",
    "    \n",
    "| State | Description | Testing |\n",
    "| ----- | ----------- | -------- |\n",
    "| S | Susceptible | Negative |\n",
    "| E | Exposed | Very weakly virus positive\n",
    "| A | Asymptomatic | Weakly virus positive\n",
    "| I<sub>1</sub> | Symptomatic early | Strongly virus positive\n",
    "| I<sub>2</sub> | Symptomatic late | Medium virus positive <br>Weakly IgM antibody positive\n",
    "| R<sub>1</sub> | Recovered early | IgM antibody positive\n",
    "| R<sub>2</sub> | Recovered late | IgM/IgG antibody positive\n",
    "| D | COVID-related death | May be virus or antibody positive\n",
    "\n",
    "\n",
    "<sub><sup>*</sup>We plan to consider partial / short-term immunity, see further discussion in [Continued research](#header_contd).</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "The below consists of the implementation of the model described above, with extended comments including assumptions, sources of data and areas to improve upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use available data up until this day; cutoff is important due to more recent data being less complete.\n",
    "CONST_DATA_CUTOFF_DATE = \"20200414\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Helper functions\n",
    "\n",
    "To preserve the single-notebook formulation, we include all packages used as well as subfunctions here\n",
    "\n",
    "To skip to the start of model implementation, <a href=\"#modelImplementation\">click here</a>!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "# Basic packages\n",
    "import numpy as np\n",
    "\n",
    "from scipy import integrate, stats, spatial\n",
    "from scipy.special import expit, binom\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd # help read excel files directly from source into pandas\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "# Building parameter/computation graph\n",
    "import inspect\n",
    "from collections import OrderedDict\n",
    "\n",
    "# OS/filesystem tools\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import cloudpickle\n",
    "\n",
    "# Distributed computing tools\n",
    "import dask\n",
    "import distributed\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup various age-group representations into our internal one, and vice versa\n",
    "def regroup_by_age(\n",
    "    inp, # first dimension is ages, others dont matter.\n",
    "    fromAgeSplits, toAgeSplits, maxAge=100., maxAgeWeight = 5.):\n",
    "    fromAgeSplits = np.concatenate([np.array([0]), fromAgeSplits, np.array([maxAge])]) # Add a zero at beginning for calculations\n",
    "    toAgeSplits = np.concatenate([np.array([0]), toAgeSplits, np.array([maxAge])]) # Add inf at end for calculations\n",
    "    def getOverlap(a, b):\n",
    "        return max(0, min(a[1], b[1]) - max(a[0], b[0]))\n",
    "    out = np.zeros((len(toAgeSplits)-1,)+inp.shape[1:])\n",
    "    for from_ind in range(1, len(fromAgeSplits)):\n",
    "        # Redistribute to the new bins by calculating how many years in from_ind-1:from_ind falls into each output bin\n",
    "        cur_out_distribution = (\n",
    "        [getOverlap(toAgeSplits[cur_to_ind-1:cur_to_ind+1],fromAgeSplits[from_ind-1:from_ind+1])  for cur_to_ind in range(1, len(toAgeSplits))]\n",
    "        )\n",
    "        \n",
    "        if cur_out_distribution[-1] > 0:\n",
    "            cur_out_distribution[-1] = maxAgeWeight # Define the relative number of ages if we have to distribute between second to last and last age groups\n",
    "\n",
    "        cur_out_distribution = cur_out_distribution/np.sum(cur_out_distribution)\n",
    "        \n",
    "        for to_ind in range(len(out)):\n",
    "            out[to_ind] += cur_out_distribution[to_ind] * inp[from_ind-1]\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "# PARAMETER DICTIONARIES AND TABLES\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# Build the nested parameter/computation graph of a single function.\n",
    "def build_paramDict(cur_func):\n",
    "    \"\"\"\n",
    "    This function iterates through all inputs of a function, \n",
    "    and saves the default argument names and values into a dictionary.\n",
    "    \n",
    "    If any of the default arguments are functions themselves, then recursively (depth-first) adds an extra field to\n",
    "    the dictionary, named <funcName + \"_params\">, that contains its inputs and arguments.\n",
    "    \n",
    "    The output of this function can then be passed as a \"kwargs\" object to the highest level function, \n",
    "    which will then pass the parameter values to the lower dictionary levels appropriately\n",
    "    \"\"\"\n",
    "    \n",
    "    paramDict = OrderedDict()\n",
    "    \n",
    "    allArgs = inspect.getfullargspec(cur_func)\n",
    "    \n",
    "    # Check if there are any default parameters, if no, just return empty dict\n",
    "    if allArgs.defaults is None:\n",
    "        return paramDict\n",
    "    \n",
    "    \n",
    "    for argname, argval in zip(allArgs.args[-len(allArgs.defaults):], allArgs.defaults):\n",
    "        # Save the default argument\n",
    "        paramDict[argname] = argval\n",
    "        # If the default argument is a function, inspect it for further \n",
    "        \n",
    "        if callable(argval):\n",
    "            # print(argname)\n",
    "            paramDict[argname+\"_params\"] = build_paramDict(argval)\n",
    "\n",
    "    return paramDict\n",
    "\n",
    "\n",
    "# Do a mapping between dictionary and parameter table row and vice versa (for convenient use)\n",
    "\n",
    "# Flatten the dictionary into a table with a single row (but many column):\n",
    "def paramDict_toTable(paramDict):\n",
    "    paramTable = pd.DataFrame()\n",
    "    def paramDictRecurseIter(cur_table, cur_dict, preString):\n",
    "        # Iterate through the dictionary to find all keys not ending in \"_params\", \n",
    "        # and add them to the table with name <preString + key>\n",
    "        # \n",
    "        # If the key doesn end in \"_params\", then append the key to preString, in call this function on the value (that is a dict)\n",
    "        for key, value in cur_dict.items():\n",
    "            if key.endswith(\"_params\"):\n",
    "                paramDictRecurseIter(cur_table, value, preString+key+\"_\")\n",
    "            else:\n",
    "                paramTable[preString+key] = [value]\n",
    "                \n",
    "        # For the rare case where we want to keep an empty dictionary, the above for cycle doesn't keep it\n",
    "        if len(cur_dict)==0:\n",
    "            paramTable[preString] = [OrderedDict()]\n",
    "                \n",
    "        return cur_table\n",
    "    \n",
    "    return paramDictRecurseIter(paramTable, paramDict, preString=\"\")\n",
    "\n",
    "\n",
    "def paramTable_toDict(paramTable, defaultDict=None):\n",
    "    # enable to pass a default dict (if paramTable is incomplete), in which we'll just add / overwrite the values\n",
    "    paramDict = defaultDict if defaultDict is not None else OrderedDict() \n",
    "    def placeArgInDictRecurse(argName, argVal, cur_dict):\n",
    "        # Find all \"_params_\" in the argName, and for each step more and more down in the dictionary\n",
    "        strloc = argName.find(\"_params_\")\n",
    "        if strloc == -1:\n",
    "            # We're at the correct level of dictionary\n",
    "            cur_dict[argName] = argVal\n",
    "            return cur_dict\n",
    "        else:\n",
    "            # step to the next level of dictionary\n",
    "            nextKey = argName[:strloc+len(\"_params_\")-1]\n",
    "            nextArgName = argName[strloc+len(\"_params_\"):]\n",
    "            if not nextKey in cur_dict:\n",
    "                cur_dict[nextKey] = OrderedDict()\n",
    "            placeArgInDictRecurse(nextArgName, argVal, cur_dict[nextKey])\n",
    "            \n",
    "        return cur_dict\n",
    "            \n",
    "    for key in paramTable.columns:\n",
    "        paramDict = placeArgInDictRecurse(key, paramTable.at[0,key], paramDict)\n",
    "        \n",
    "    return paramDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"modelImplementation\"></a>\n",
    "# Model implementation\n",
    "\n",
    "The model is governed by these two main tensors:\n",
    "- State tensor: a 4th order tensor containing axes:\n",
    "    - Age groups\n",
    "    - Health states\n",
    "    - Isolation states\n",
    "    - Testing states\n",
    "    \n",
    "    In our extended state tensor formulation, we also keep track of not just people currently in each state, but also people newly arriving to each state, as a large number of available datasets refer to \"new cases\" or \"new hospitalisations\" each day, rather than current state occupancies normally represented by ODE solutions.   \n",
    "    \n",
    "    \n",
    "- Dynamic state transition rate tensor\n",
    "    - Rates that govern all allowed transitions between states\n",
    "    - Dynamically recomputed every iteration, based on number of infected, their current social mixing and number and types of tests available, amongst other variables.\n",
    "    - Briefly:\n",
    "        - No transition between age groups\n",
    "        - No transitions between testing states without performing a test\n",
    "        - No transitions into S or out of D and R_IgG health states\n",
    "    - Allowed transitions are as showcased in the model image above\n",
    "    - Represented by a 7th order, sparse tensor, containing all transitions except age (unimportant due to relatively short time scales compared to coarse age grouping)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "NOTICE\n",
    "------\n",
    "THE \"MODEL IMPLEMENTATION\" SECTION CONTAINS A LARGE NUMBER OF PARAMETER VALUES SET TO A DEFAULT VALUE.\n",
    "THESE ARE LARGELY INFORMED BY DATA, BUT NOT FIXED!\n",
    "THEY ARE VARIED DURING THE FITTING OF THE MODEL, ACCORDING TO HOW UNCERTAIN WE ARE IN THE PARAMETER\n",
    "```\n",
    "\n",
    "The priors are defined <a href=\"#defineEnsemblePriors\">below the model</a>. Although many of our uncertain / weak assumptions are signalled by \"TODO\" comments, we feel that the overall conclusions would not be affected by finding better parameter values, especially given our fitting and exploration approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The state tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Dimensions\n",
    "\n",
    "# Health states (S, E and D are fixed to 1 dimension)\n",
    "nI_symp = 2 # number of sympyomatic infected states\n",
    "nI = 2+nI_symp # number of total infected states (disease stages), the +2 are Exposed and I_nonsymptomatic\n",
    "nR = 2 # number of recovery states (antibody development post-disease, IgM and IgG are two stages)\n",
    "nHS = 2+nI+nR # number of total health states, the +2: S, D are suspectible and dead\n",
    "\n",
    "# Age groups (risk groups)\n",
    "nAge = 9 # In accordance w Imperial #13 report (0-9, 10-19, ... 70-79, 80+)\n",
    "\n",
    "# Isolation states\n",
    "nIso = 4 # None/distancing, Case isolation, Hospitalised, Hospital staff\n",
    "\n",
    "# Testing states\n",
    "nTest = 4 # untested/negative, Virus positive, Antibody positive, Both positive\n",
    "\n",
    "\n",
    "stateTensor = np.zeros((nAge, nHS, nIso, nTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition rates (1 / day)\n",
    "\n",
    "The full transition rate structure is an 8th order tensor, \n",
    "mapping from any 4D state in the state tensor, to any other 4D state in the state tensor\n",
    "\n",
    "However, many of these transitions are non-sensical (ie a 3 year old cannot suddenly become 72, or a dead person be infected again), therefore during the construction of the full model below, we fill in the rates on all \"allowed\" transitions.\n",
    "\n",
    "We attempt to do so based on existing data either describing particular rates (like COVID-related hospitalisation),\n",
    "or data that helps constrain the product or ratios of multiple rates (such as the R0, or the case fatality ratio [noting this latter depends on testing policy and test availability]).\n",
    "\n",
    "Further, to massively reduce the number of weakly constrained parameters, we will approximate many of the weakly correlated transition rates as rank 1 (uncorrelated) matrices. For example the rate of hospitalisation for a patient at a given age and stage of infection will be computed as a product of two indepent rates, one based purely on the age (older people are generally more at risk of hospitalisation), and the other purely on how far the patient has progressed into the disease. This allows us to estimate more of required parameters from available published data.\n",
    "\n",
    "There of course still is a lot of uncertainty about how the virus behaves, and all of the data that we use is likely uncomplete and noisy. In order to better represent the things we do not know, we use advanced machine learning techniques, and investigate many possible scenarios (settings of parameters) and for all analyses we retain all plausible scenarios (various parameter settings that explain the available data well enough).\n",
    "\n",
    "Any policies we suggest for the near future are investigated for all plausible scenarios, such that decision makers know how likely each one will work as expected in these uncertain times. We further note that as we progress further into the pandemic, the number of plausible scenarios reduces more and more, enabling us to see the way out clearer and clearer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population (data from Imperial #13 ages.csv/UK)\n",
    "agePopulationTotal = 1000.*np.array([8044.056,7642.473,8558.707,9295.024,8604.251,9173.465,7286.777,5830.635,3450.616])\n",
    "#agePopulationTotal = 1000.*pd.read_csv(\"https://raw.githubusercontent.com/ImperialCollegeLondon/covid19model/master/data/ages.csv\").iloc[3].values[2:]\n",
    "# Currently: let's work with england population only instead of full UK, as NHS England + CHESS data is much clearer than other regions\n",
    "agePopulationTotal *= 55.98/66.27 # (google england/uk population 2018, assuming age dist is similar)\n",
    "agePopulationRatio = agePopulationTotal/np.sum(agePopulationTotal)\n",
    "\n",
    "# Helper function to adjust average rates to age-aware rates\n",
    "def adjustRatesByAge_KeepAverageRate(rate, ageRelativeAdjustment, agePopulationRatio=agePopulationRatio, maxOutRate=10):\n",
    "    \"\"\"This is a helper function and wont be picked up as a model parameter!\"\"\"\n",
    "    if rate == 0:\n",
    "        return np.zeros_like(ageRelativeAdjustment)\n",
    "    if rate >= maxOutRate:\n",
    "        warnings.warn(\"covidTesting::adjustRatesByAge_KeepAverageRate Input rate {} > maxOutRate {}, returning input rates\".format(rate, maxOutRate))\n",
    "        return rate*np.ones_like(ageRelativeAdjustment)\n",
    "    out = np.zeros_like(ageRelativeAdjustment)\n",
    "    out[0] = maxOutRate+1 # just to start the while loop below\n",
    "    while np.sum(out>=maxOutRate)>0:\n",
    "        corrFactor = np.sum(agePopulationRatio/(1+ageRelativeAdjustment))\n",
    "        out =  rate * (1+ageRelativeAdjustment) * corrFactor\n",
    "        if np.sum(out>=maxOutRate)>0:\n",
    "            warnings.warn(\"covidTesting::adjustRatesByAge_KeepAverageRate Adjusted rate larger than {} encountered, reducing ageAdjustment variance by 10%\".format(maxOutRate))\n",
    "            #print(out)\n",
    "            tmp_mean = np.mean(ageRelativeAdjustment)\n",
    "            ageRelativeAdjustment = tmp_mean + np.sqrt(0.9)*(ageRelativeAdjustment-tmp_mean)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting infected\n",
    "# ------------------\n",
    "# We wish to calibrate overall infection rates to match \n",
    "# - previous R0 estimates, \n",
    "# - available age-attack-ratios,\n",
    "\n",
    "\n",
    "\n",
    "# Age-dependent mixing affects state transition S -> I1 (data available eg Imperial #13 report)\n",
    "# The mixing-related data is nowhere to be found!\n",
    "# This is an Age x Age symmetric matrix, showing which groups mix with which other ones.\n",
    "# Data from DOI: 10.1097/EDE.0000000000001047 via http://www.socialcontactdata.org/tools/ interactive tool in data folder\n",
    "# This is assumed to be contacts per day (but may need to be time-rescaled)\n",
    "ageSocialMixingBaseline = pd.read_csv('data/socialcontactdata_UK_Mossong2008_social_contact_matrix.csv', sep=',').iloc[:,1:].values\n",
    "ageSocialMixingDistancing = pd.read_csv('data/socialcontactdata_UK_Mossong2008_social_contact_matrix_with_distancing.csv', sep=',').iloc[:,1:].values\n",
    "\n",
    "# Symmetrise these matrices (not sure why they aren't symmetric)\n",
    "ageSocialMixingBaseline = (ageSocialMixingBaseline+ageSocialMixingBaseline.T)/2.\n",
    "ageSocialMixingDistancing = (ageSocialMixingDistancing+ageSocialMixingDistancing.T)/2.\n",
    "\n",
    "# For simplicity, let's assume scenario of perfect isolation in state-issued home quarantine, see commented below for alternatives\n",
    "ageSocialMixingIsolation = np.zeros_like(ageSocialMixingBaseline) \n",
    "#isolationEffectComparedToDistancing = 3. # TODO - find better numbers for proper isolation mixing estimation!\n",
    "#ageSocialMixingIsolation = ageSocialMixingBaseline/(isolationEffectComparedToDistancing * np.mean(ageSocialMixingBaseline/ageSocialMixingDistancing))\n",
    "\n",
    "\n",
    "\n",
    "# For the S->I1 transition we also need a product mapping, \n",
    "# as the AS->AI1 rate is variable and depend on all AI via social mixing (ages) and transmission rates (I stages)\n",
    "# this vector is nI long only, calibrated together with other variables to reproduce overall R0\n",
    "# These numbers should represent rate of transmission given contact [will be multiplied by social mixing matrices]\n",
    "transmissionInfectionStage = np.array([0.001, 0.1, 0.6, 0.5]) # We vary this during model fitting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Infected in the Hospital\n",
    "# ---------------------------------------\n",
    "\n",
    "# The general experience is that infections spread faster in a hospital environment, \n",
    "# we capture this intuition with an age-independent but increased \"social Mixing\" amongst hospital patients and staff\n",
    "\n",
    "# TODO - This requires further data-driven calibration!\n",
    "\n",
    "# Capture S->I1 within hospital, given the number of total infected inside hospitals\n",
    "elevatedMixingRatioInHospital = 3. # TODO - fact check this number, atm just set based on intuition\n",
    "# Called \"Nosocomial viral infection\", some data: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5414085/\n",
    "# HAP: hospital acquired pneumonia, apparently quite common\n",
    "# more data: https://cmr.asm.org/content/14/3/528\n",
    "# on covid-19: https://www.thelancet.com/journals/lanpub/article/PIIS2468-2667(20)30073-6/fulltext \"Nosocomial infection risk among health-care workers and patients has been identified as a research gap to be prioritised in the next few months by WHO.\"\n",
    "withinHospitalSocialMixing = elevatedMixingRatioInHospital * np.sum(np.dot(agePopulationRatio, ageSocialMixingBaseline))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also add new infected from travelling based on time-within-simulation\n",
    "\n",
    "# TODO - get real travel data to make these numbers more realistic. For now based on the following assumptions:\n",
    "# - people's age distribution in travel is square of the usual age distribution\n",
    "# - travel rates declined from a base rate as a sigmoid due to border closures, with given mean and slope\n",
    "# - infection rates due to travel are modelled as a gamma pdf over time, with given peak value, loc, and scale parameter\n",
    "def trFunc_travelInfectionRate_ageAdjusted(\n",
    "    t, # Time (int, in days) within simulation\n",
    "    \n",
    "    travelMaxTime = 200,\n",
    "    travelBaseRate = 5e-4, # How many people normally travel back to the country per day # TODO - get data\n",
    "    travelDecline_mean = 15.,\n",
    "    travelDecline_slope = 1.,\n",
    "    \n",
    "    travelInfection_peak = 1e-1,\n",
    "    travelInfection_maxloc = 10.,\n",
    "    travelInfection_shape = 2.,\n",
    "\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    tmpTime = np.arange(travelMaxTime)\n",
    "    # nAge x T TODO get some realistic data on this\n",
    "    travelAgeRateByTime = travelBaseRate * np.outer(agePopulationRatio, 1-expit((tmpTime-travelDecline_mean)/travelDecline_slope))\n",
    "    \n",
    "    \n",
    "    # 1 x T TODO get some realistic data on this, maybe make it age weighted\n",
    "    travelContractionRateByTime = stats.gamma.pdf(tmpTime, a=travelInfection_shape, loc=0., scale=travelInfection_maxloc/(travelInfection_shape-1))\n",
    "    travelContractionRateByTime = travelInfection_peak*travelContractionRateByTime/np.max(travelContractionRateByTime)\n",
    "\n",
    "    \n",
    "    if t >= travelAgeRateByTime.shape[-1]:\n",
    "        return np.zeros(travelAgeRateByTime.shape[0])\n",
    "    else:\n",
    "        return travelAgeRateByTime[:,int(t)] * travelContractionRateByTime[int(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall new infections include within quarantine and hospital infections\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def trFunc_newInfections_Complete(\n",
    "    stateTensor,\n",
    "    policySocialDistancing, # True / False, no default because it's important to know which one we use at any moment!\n",
    "    policyImmunityPassports, # True / False, no default because it's important to know which one we use at any moment!\n",
    "    ageSocialMixingBaseline = ageSocialMixingBaseline,\n",
    "    ageSocialMixingDistancing = ageSocialMixingDistancing,\n",
    "    ageSocialMixingIsolation = ageSocialMixingIsolation,\n",
    "    withinHospitalSocialMixing = withinHospitalSocialMixing,\n",
    "    transmissionInfectionStage = transmissionInfectionStage,\n",
    "    \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    All new infections, given infected people on all different isolation states (normal, home, hospital)\n",
    "    We use the following assumptions:\n",
    "    \n",
    "    - Infectiousness only depends on infection stage, not age or location\n",
    "    \n",
    "    - Hospitalised people are assumed to only mix with other hospitalised people (this includes staff!), \n",
    "    in a non-age-dependent manner: withinHospitalSocialMixing\n",
    "    \n",
    "    If policySocialDistancing is True\n",
    "    - Non- and home-isolated people mix with non- and home isolated via ageSocialMixingDistancing (averaging interactions)\n",
    "    \n",
    "    If policySocialDistancing is False, we assume home-isolation is taken more seriously, but with little effect on non-isolated people \n",
    "    - Non-isolated people mix with each other via ageSocialMixingBaseline, and with home-isolated people via ageSocialMixingIsolation\n",
    "    - Home-isolated people do not mix with each other\n",
    "    \n",
    "    This separation will help disentangle the effects of simply a blanket lessening of social distancing \n",
    "    (keeping the policy True but with less effective ageSocialMixingDistancing matrix),\n",
    "    vs case isolation (policy = False, but with serious ageSocialMixingIsolation)\n",
    "    \"\"\"\n",
    "    \n",
    "    ageIsoContractionRate = np.zeros((nAge, nIso, nTest))\n",
    "    \n",
    "    \n",
    "    # Add non-hospital infections\n",
    "    #--------------------------------\n",
    "    \n",
    "    curNonIsolatedSocialMixing = ageSocialMixingDistancing if policySocialDistancing else ageSocialMixingBaseline\n",
    "        \n",
    "    # Add baseline interactions only between non-isolated people\n",
    "    for k1 in [0,3]:\n",
    "        for k2 in [0,3]:\n",
    "            ageIsoContractionRate[:,k1,:] += np.expand_dims(\n",
    "                np.matmul(\n",
    "                    curNonIsolatedSocialMixing,\n",
    "                    np.einsum('ijl,j->i',\n",
    "                        stateTensor[:,1:(nI+1),k2,:], transmissionInfectionStage) # all infected in non-isolation\n",
    "                ),\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "    if policyImmunityPassports:\n",
    "        # If the immunity passports policy is on, everyone who tested antibody positive, can roam freely\n",
    "        # Therefore replace the interactions between people with testingState = 2 with ageSocialMixingBaseline\n",
    "        # we do this by using the distributive property of matrix multiplication, and adding extra interactions\n",
    "        # \"ageSocialMixingBaseline\"-\"curNonIsolatedSocialMixing\" with each other (this is zero if no social distancing!)\n",
    "        # TODO - this is a bit hacky?, but probably correct - double check though!\n",
    "        for k1 in [0,3]:\n",
    "            for k2 in [0,3]:\n",
    "                ageIsoContractionRate[:,k1,2:] += np.matmul(\n",
    "                        ageSocialMixingBaseline-curNonIsolatedSocialMixing,\n",
    "                        np.einsum('ijk,j->ik',\n",
    "                            stateTensor[:,1:(nI+1),k2,2:], transmissionInfectionStage) # all infected in non-isolation\n",
    "                    )\n",
    "\n",
    "    # Add isolation interactions only between isolated and non-isolated people\n",
    "    # non-isolated contracting it from isolated\n",
    "    for k1 in [0,3]:\n",
    "        ageIsoContractionRate[:,k1,:] += np.expand_dims(\n",
    "            np.matmul(\n",
    "                ageSocialMixingIsolation,\n",
    "                np.einsum('ijl,j->i',\n",
    "                    stateTensor[:,1:(nI+1),1,:], transmissionInfectionStage) # all infected in isolation\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # isolated contracting it from non-isolated\n",
    "    for k1 in [0,3]:\n",
    "        ageIsoContractionRate[:,1,:] += np.expand_dims(\n",
    "            np.matmul(\n",
    "                ageSocialMixingIsolation,\n",
    "                np.einsum('ijl,j->i',\n",
    "                    stateTensor[:,1:(nI+1),k1,:], transmissionInfectionStage) # all infected in non-hospital, non-isolation\n",
    "            ),\n",
    "            axis = 1\n",
    "        )\n",
    "        \n",
    "        # isolated cannot contracting it from another isolated\n",
    "    \n",
    "    \n",
    "    # Add in-hospital infections (of hospitalised patients, and staff)\n",
    "    #--------------------------------\n",
    "    # (TODO - within hospitals we probably want to take into effect the testing state; \n",
    "    #      tested people are better isolated and there's less mixing)\n",
    "    \n",
    "    ageIsoContractionRate[:,2:,:] += np.expand_dims(\n",
    "            withinHospitalSocialMixing *\n",
    "            np.einsum('ijkl,j->i',\n",
    "                stateTensor[:,1:(nI+1),2:,:], transmissionInfectionStage), # all infected in hospital (sick or working)\n",
    "        axis = (1,2))\n",
    "\n",
    "    \n",
    "    return ageIsoContractionRate/np.sum(stateTensor) # Normalise the rate by total population\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospitalisation and hospital staff\n",
    "\n",
    "Disease progression in severe cases naturally leads to hospitalisation before death. \n",
    "One of the important policy questions we wish to estimate is how many people at any one time would require a hospital bed during the treatment of their disease.\n",
    "\n",
    "Hospitalisation is generally a simple situation modeling wise. People with either symptomatic infection (I3-...In states), or for other sicknesses (baseline hospitalisation) end up in hospital. People in S health state may return to non-hospitalised S state, however people in (informed, see later) I state generally remain in hospital until they recovered or dead.\n",
    "\n",
    "Home quarantine / social distancing is a different situation. Unlike other reports, here we do not (yet) wish to disentagle the effects of individual quarantine operations (school closures, working from home, social distancing), but rather investigate the effects of current full lockdown (coming into effect on 24 March in the UK), versus testing-based informed individual quarantining.\n",
    "\n",
    "Numerically:\n",
    "\n",
    "- People in home isolation change their social mixing patterns. The overall social mixing matrix between people in no isolation and home has been estimated via the http://www.socialcontactdata.org/tools/ software, see details in the data_cleaning notebook, this will determine the S->I transition overall.\n",
    "\n",
    "- People in hospitals (sick) dramatically reduce their contacts outside the hospital, but increase the chance of transmission within the hospitalised community. For the purpose of this simulation, hospital staff will also in effect be suspecitble to higher risk of infection due to \"hospitalised\" patients and they also keep their normal interaction. \n",
    "\n",
    "- Reported numbers regarding pressure on the health system will report both COVID-19 and non-COVID-19 patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Hospitalised\n",
    "# ---------------------------------------\n",
    "\n",
    "# Describe the transitions to-from hospitals \n",
    "# Note that this implementation will assume that hospitalisation takes an extra day,\n",
    "# due to the discrete nature of the simulation, might need to be re-thought. \n",
    "# -> if simulation of a single day is done in multiple steps (first disease progression, then potential hospitalisation),\n",
    "#.    then this problem is avoided. Can do the same with testing.\n",
    "\n",
    "# Further we assume that hospitalisation does not change health state, \n",
    "# but if happens in a non-S state, then it persists until R1 or D \n",
    "# (this may need to be relaxed for early untested I states, where the hospitalisation is not COVID-related).\n",
    "\n",
    "# Hospitalisation mainly depends on disease severity\n",
    "# Baseline hospitalisation rate (Data from Scotland: https://www.isdscotland.org/Health-Topics/Hospital-Care/Publications/Acute-Hospital-Publication/data-summary/)\n",
    "#hospitalisationRateBaseline = 261278./(91.*(5.425*10**6)) # hospitalisation / (period in days * population) -> frac of pop hospitalised per day\n",
    "#hospitalisationRecoveryRateBaseline = 1./4.2 # inverse of mean length of stay in days\n",
    "\n",
    "# Larger data driver approaches, with age distribution, see data_cleaning_R.ipynb for details\n",
    "ageHospitalisationRateBaseline = pd.read_csv('data/clean_hosp-epis-stat-admi-summ-rep-2015-16-rep_table_6.csv', sep=',').iloc[:,-1].values\n",
    "ageHospitalisationRecoveryRateBaseline = 1./pd.read_csv('data/clean_10641_LoS_age_provider_suppressed.csv', sep=',').iloc[:,-1].values\n",
    "\n",
    "# Calculate initial hospitalisation (occupancy), that will be used to initialise the model\n",
    "initBaselineHospitalOccupancyEquilibriumAgeRatio = ageHospitalisationRateBaseline/(ageHospitalisationRateBaseline+ageHospitalisationRecoveryRateBaseline)\n",
    "\n",
    "\n",
    "# Take into account the NHS work-force in hospitals that for our purposes count as \"hospitalised S\" population, \n",
    "# also unaffected by quarantine measures\n",
    "ageNhsClinicalStaffPopulationRatio = pd.read_csv('data/clean_nhsclinicalstaff.csv', sep=',').iloc[:,-1].values\n",
    "\n",
    "# Extra rate of hospitalisation due to COVID-19 infection stages\n",
    "# TODO - find / estimate data on this (unfortunately true rates are hard to get due to many unknown cases)\n",
    "# Symptom to hospitalisation is 5.76 days on average (Imperial #8)\n",
    "\n",
    "infToHospitalExtra = np.array([1e-4, 1e-3, 2e-2, 1e-2])\n",
    "\n",
    "# We do know at least how age affects these risks:\n",
    "\n",
    "# For calculations see data_cleaning_py.ipynb, calculations from CHESS dataset as per 05 Apr\n",
    "relativeAdmissionRisk_given_COVID_by_age = np.array([-0.94886625, -0.96332087, -0.86528671, -0.79828999, -0.61535305,\n",
    "       -0.35214767,  0.12567034,  0.85809052,  3.55950368])\n",
    "\n",
    "riskOfAEAttandance_by_age = np.array([0.41261361, 0.31560648, 0.3843979 , 0.30475704, 0.26659415,\n",
    "       0.25203475, 0.24970244, 0.31549102, 0.65181376])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Build the transition tensor from any non-hospitalised state to a hospitalised state \n",
    "# (being in home quarantine is assumed to affect only the infection probability [below], not the hospitalisation probability)\n",
    "# caseIsolationHospitalisationRateAdjustment = 1.\n",
    "\n",
    "# This function takes as input the number of people in given age and health state, and in any non-hospitalised state\n",
    "# and returns the number of people staying in the same age and health state, \n",
    "# but now hospitalised (the rest of people remain in whatever state they were in)\n",
    "\n",
    "def trFunc_HospitalAdmission(\n",
    "    ageHospitalisationRateBaseline = ageHospitalisationRateBaseline,\n",
    "    infToHospitalExtra = infToHospitalExtra,\n",
    "    ageRelativeExtraAdmissionRiskToCovid = relativeAdmissionRisk_given_COVID_by_age * riskOfAEAttandance_by_age,\n",
    "    \n",
    "    **kwargs\n",
    "    ):\n",
    "    \n",
    "    # This tensor will pointwise multiply an nAge x nHS slice of the stateTensor\n",
    "    trTensor_HospitalAdmission = np.zeros((nAge, nHS))  \n",
    "    \n",
    "    ageAdjusted_infToHospitalExtra = copy.deepcopy(np.repeat(infToHospitalExtra[np.newaxis],nAge,axis=0))\n",
    "    for ii in range(ageAdjusted_infToHospitalExtra.shape[1]):\n",
    "        # Adjust death rate by age dependent disease severity\n",
    "        ageAdjusted_infToHospitalExtra[:,ii] = adjustRatesByAge_KeepAverageRate(\n",
    "            infToHospitalExtra[ii], \n",
    "            ageRelativeAdjustment=ageRelativeExtraAdmissionRiskToCovid\n",
    "        )\n",
    "    \n",
    "    # Add baseline hospitalisation to all non-dead states\n",
    "    trTensor_HospitalAdmission[:,:-1] += np.expand_dims(ageHospitalisationRateBaseline,-1)\n",
    "\n",
    "    # Add COVID-caused hospitalisation to all infected states (TODO: This is summation of rates for independent processes, should be correct, but check)\n",
    "    trTensor_HospitalAdmission[:,1:(nI+1)] += ageAdjusted_infToHospitalExtra\n",
    "    \n",
    "    return trTensor_HospitalAdmission\n",
    "\n",
    "# Recovery rates (hospital discharge)\n",
    "# ------------------------------------\n",
    "\n",
    "# Higher-than-normal discharge rate for people who recovered (as they were likely to be in hospital mostly due to the virus)\n",
    "# TODO - check with health experts if this is correct assumption; probably also depends on testing state\n",
    "\n",
    "def trFunc_HospitalDischarge(\n",
    "    ageHospitalisationRecoveryRateBaseline = ageHospitalisationRecoveryRateBaseline,\n",
    "    dischargeDueToCovidRateMultiplier = 3.,\n",
    "    \n",
    "    **kwargs\n",
    "    ):\n",
    "    \n",
    "    trTensor_HospitalDischarge = np.zeros((nAge, nHS))\n",
    "\n",
    "    # Baseline discharges apply to all non-symptomatic patients (TODO: take into account testing state!)\n",
    "    trTensor_HospitalDischarge[:, :3] += ageHospitalisationRecoveryRateBaseline[:,np.newaxis]\n",
    "\n",
    "    # No discharges for COVID symptomatic people from the hospital until they recover\n",
    "    # TODO - check with health experts if this is correct assumption; probably also depends on testing state\n",
    "    trTensor_HospitalDischarge[:, 3:5] = 0.\n",
    "\n",
    "\n",
    "    trTensor_HospitalDischarge[:, 5:7] = dischargeDueToCovidRateMultiplier * ageHospitalisationRecoveryRateBaseline[:,np.newaxis]\n",
    "    \n",
    "    return trTensor_HospitalDischarge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TODO - think of how the latest changes (no prenatal care, no elective surgeries, etc) changed the default hospitalisation rate\n",
    "#trTensor_HospitalAdmission[:,5]\n",
    "    \n",
    "# TODO!!! - adjust disease progression transitions so that it shifts direct death probabilities to hospitalised death probabilities    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease progression\n",
    "\n",
    " - assumed to be strictly age and infection stage dependent distributions (progression rates), doesn't depend on other people\n",
    " - distinct states represent progression, not necessarly time, but only forward progression is allowed, and the inverse of rates represent average number of days in progression\n",
    " - there is a small chance of COVID death from every state, but we assume death is most often preceeded by hospitalisation\n",
    " - there is a chance of recovery (and becoming immunised) from every state\n",
    "\n",
    "We wish to calibrate these disease progression probabilities to adhere to observed data / earlier models\n",
    "- serial interval distribution suggests time-to-transmission of Gamma(6.5 days, 0.62) MODEL [Imperial #13]\n",
    "Symptom progression (All params with relatively wide confidence intervals)\n",
    "- infect-to-symptom onset is assumed 5 days mean MODEL [AceMod, https://arxiv.org/pdf/2003.10218.pdf]\n",
    "- symptom-to-death is 16 days DATA_WEAK [Imperial #8]\n",
    "- symptom-to-discharge is 20.5 days DATA_WEAK [Imperial #8]\n",
    "- symptom-to-hospitalisation is 5.76 days DATA_WEAK [Imperial #8]\n",
    "- hospitalisation-to-recovery is 14.51 days DATA_WEAK [Imperial #8]\n",
    "all the above in Imperial #8 is largely age dependent. Raw data available in data/ImperialReport8_subset_international_cases_2020_03_11.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on England data (CHESS and NHS England)\n",
    "\n",
    "\n",
    "\n",
    "# I want a way to keep this as the \"average\" disease progression, but modify it such that old people have less favorable outcomes (as observed)\n",
    "# But correspondingly I want people at lower risk to have more favorable outcome on average\n",
    "\n",
    "# For calculations see data_cleaning_py.ipynb, calculations from NHS England dataset as per 05 Apr\n",
    "relativeDeathRisk_given_COVID_by_age = np.array([-0.99742186, -0.99728639, -0.98158438, -0.9830432 , -0.82983414,\n",
    "       -0.84039294,  0.10768979,  0.38432409,  5.13754904])\n",
    "\n",
    "#ageRelativeDiseaseSeverity = np.array([-0.8, -0.6, -0.3, -0.3, -0.1, 0.1, 0.35, 0.4, 0.5]) # FIXED (above) - this is a guess, find data and fix\n",
    "#ageRelativeRecoverySpeed = np.array([0.2]*5+[-0.1, -0.2, -0.3, -0.5]) # TODO - this is a guess, find data and fix\n",
    "ageRelativeRecoverySpeed = np.array([0.]*9) # For now we make it same for everyone, makes calculations easier\n",
    "\n",
    "# For calculations see data_cleaning_py.ipynb, calculations from NHS England dataset as per 05 Apr\n",
    "caseFatalityRatioHospital_given_COVID_by_age = np.array([0.00856164, 0.03768844, 0.02321319, 0.04282494, 0.07512237,\n",
    "       0.12550367, 0.167096  , 0.37953452, 0.45757006])\n",
    "\n",
    "\n",
    "def trFunc_diseaseProgression(\n",
    "    # Basic parameters to adhere to\n",
    "    nonsymptomatic_ratio = 0.86,\n",
    "    \n",
    "    # number of days between measurable events\n",
    "    infect_to_symptoms = 5.,\n",
    "    #symptom_to_death = 16.,\n",
    "    symptom_to_recovery = 10., # 20.5, #unrealiticly long for old people\n",
    "    symptom_to_hospitalisation = 5.76,\n",
    "    hospitalisation_to_recovery = 14.51,\n",
    "    IgG_formation = 15.,\n",
    "    \n",
    "    # Age related parameters\n",
    "    # for now we'll assume that all hospitalised cases are known (overall 23% of hospitalised COVID patients die. 9% overall case fatality ratio)\n",
    "    caseFatalityRatioHospital_given_COVID_by_age = caseFatalityRatioHospital_given_COVID_by_age, \n",
    "    ageRelativeRecoverySpeed = ageRelativeRecoverySpeed,\n",
    "    \n",
    "    # Unknown rates to estimate\n",
    "    nonsymp_to_recovery = 15.,\n",
    "    inverse_IS1_IS2 = 4.,\n",
    "    \n",
    "    \n",
    "    **kwargs\n",
    "    ):\n",
    "    # Now we have all the information to build the age-aware multistage SIR model transition matrix\n",
    "    # The full transition tensor is a sparse map from the Age x HealthState x isolation state to HealthState, \n",
    "        # and thus is a 4th order tensor itself, representing a linear mapping \n",
    "        # from \"number of people aged A in health state B and isolation state C to health state D.\n",
    "    trTensor_diseaseProgression = np.zeros((nAge, nHS, nIso, nHS))\n",
    "\n",
    "    \n",
    "    # Use basic parameters to regularise inputs\n",
    "    E_IS1 = 1./infect_to_symptoms\n",
    "    # Numbers nonsymptomatic is assumed to be 86% -> E->IN / E-IS1 = 0.86/0.14\n",
    "    E_IN = 0.86/0.14 * E_IS1\n",
    "    \n",
    "    # Nonsymptomatic recovery\n",
    "    IN_R1 = 1./nonsymp_to_recovery\n",
    "    \n",
    "    IS1_IS2  = 1./inverse_IS1_IS2\n",
    "    \n",
    "    IS2_R1 = 1./(symptom_to_recovery-inverse_IS1_IS2)\n",
    "    \n",
    "    R1_R2 = 1./IgG_formation\n",
    "    \n",
    "    \n",
    "    # Disease progression matrix # TODO - calibrate (together with transmissionInfectionStage)\n",
    "    # rows: from-state, cols: to-state (non-symmetric!)\n",
    "    # - this represent excess deaths only, doesn't contain baseline deaths!\n",
    "\n",
    "    # Calculate all non-serious cases that do not end up in hospitals. \n",
    "    # Note that we only have reliable death data from hospitals (NHS England), so we do not model people dieing outside hospitals\n",
    "    diseaseProgBaseline = np.array([\n",
    "    # to: E,   IN,   IS1,   IS2,    R1,   R2,   D       \n",
    "        [  0 , E_IN, E_IS1,    0,   0,     0,   0   ], # from E\n",
    "        [  0,   0,     0,   0,    IN_R1,   0,   0   ], # from IN\n",
    "        [  0 ,  0,     0, IS1_IS2,  0,     0,    0 ], # from IS1\n",
    "        [  0 ,  0,     0,    0,  IS2_R1,   0,   0  ], # from IS2\n",
    "        [  0 ,  0,     0,    0,    0,    R1_R2,  0   ], # from R1\n",
    "        [  0 ,  0,     0,    0,    0,     0,   0   ], # from R2\n",
    "        [  0 ,  0,     0,    0,    0,     0,   0   ] # from D\n",
    "    ])\n",
    "    \n",
    "    ageAdjusted_diseaseProgBaseline = copy.deepcopy(np.repeat(diseaseProgBaseline[np.newaxis],nAge,axis=0))\n",
    "\n",
    "    # Modify all death and R1 rates:\n",
    "    for ii in range(ageAdjusted_diseaseProgBaseline.shape[1]):\n",
    "        # Adjust death rate by age dependent disease severity\n",
    "        ageAdjusted_diseaseProgBaseline[:,ii,-1] = adjustRatesByAge_KeepAverageRate(\n",
    "            ageAdjusted_diseaseProgBaseline[0,ii,-1], \n",
    "            ageRelativeAdjustment=relativeDeathRisk_given_COVID_by_age\n",
    "        )\n",
    "\n",
    "        # Adjust recovery rate by age dependent recovery speed\n",
    "        ageAdjusted_diseaseProgBaseline[:,ii,-3] = adjustRatesByAge_KeepAverageRate(\n",
    "            ageAdjusted_diseaseProgBaseline[0,ii,-3], \n",
    "            ageRelativeAdjustment=ageRelativeRecoverySpeed,\n",
    "            agePopulationRatio=agePopulationRatio\n",
    "        )\n",
    "    \n",
    "    ageAdjusted_diseaseProgBaseline_Hospital = copy.deepcopy(ageAdjusted_diseaseProgBaseline)\n",
    "    # Calculate hospitalisation based rates, for which we do have data. Hospitalisation can end up with deaths\n",
    "    \n",
    "    # Make sure that the ratio of recoveries in hospital honour the case fatality ratio appropriately\n",
    "    # IS2 -> death\n",
    "    ageAdjusted_diseaseProgBaseline_Hospital[:,3,-1] = (\n",
    "        # IS2 -> recovery\n",
    "        ageAdjusted_diseaseProgBaseline_Hospital[:,3,-3] * (\n",
    "            # multiply by cfr / (1-cfr) to get correct rate towards death\n",
    "            caseFatalityRatioHospital_given_COVID_by_age/(\n",
    "                 1 -  caseFatalityRatioHospital_given_COVID_by_age)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # TODO - time to death might be incorrect overall without an extra delay state, especially for young people\n",
    "\n",
    "    # Non-hospitalised disease progression\n",
    "    for i1 in [0,1,3]:\n",
    "        trTensor_diseaseProgression[:,1:,i1,1:] = ageAdjusted_diseaseProgBaseline\n",
    "\n",
    "    # hospitalised disease progression\n",
    "    trTensor_diseaseProgression[:,1:,2,1:] = ageAdjusted_diseaseProgBaseline_Hospital\n",
    "        \n",
    "    \n",
    "    return trTensor_diseaseProgression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "In this section we describe multiple types of tests (PCR, antigen and antibody), and estimate their sensitivity and specificity in different health stages. These are thought to be the same for patients of all ages, and isolation states at this time.\n",
    "\n",
    "We then model the transitions to other testing states, which are largely policy-based.\n",
    "\n",
    "To model the current data (up to 03 April 2020):\n",
    "- only PCR tests have been done in the UK\n",
    "- PCR tests are thought to be carried out almost exclusively on symptomatic patients, to determine if their symptoms are caused by SARS-CoV2 or some other infection (this helps us determine the baseline ILI symptoms in practice, to predict true negative rates of the tests given the SARS-infected vs non-SARS-infected (but ILI symptom producing) populations).\n",
    "\n",
    "One aim of this complete model is to enable policy makers to make decisions now, based on predicted test availability in the future, therefore most testing-related concerns will be hypotheticals. That said, we aim to accurately model the tests' capabilities based on extensive literature research, and also aim to bring stable policy-level outcomes despite the actual numbers may be inaccurate.\n",
    "\n",
    "Two important questions answered by integrating this section into the epidemiology model above will be:\n",
    "    \n",
    "    1. In what ratio we should produce antibody and antigen lateral flow immunoassay tests? They require the same production capabilities and reagents, there is a question ideally suited to the policy making level\n",
    "    \n",
    "    2. At what level of testing capabilities (PCR, antigen and antibody) can the country lessen the complete lockdown, without risking lives or overburdening the NHS?\n",
    "    \n",
    "    \n",
    "    \n",
    "API:\n",
    "\n",
    "- trFunc_testing(stateTensor, t, policyFunc, testSpecifications, trFunc_testCapacity):\n",
    "    - This is the main transition rate function, it returns transition rates from and to all testing states\n",
    "\n",
    "- policyFunc\n",
    "    - Returns a testing policy about what states are tested with how many of which test\n",
    "    \n",
    "- testSpecifications\n",
    "    - Details the FPR/FNR of individual tests given the health state\n",
    "    \n",
    "- trFunc_testCapacity(t)\n",
    "    - outputs how many tests are available at time t of the different test types modelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "# ---------------\n",
    "\n",
    "\n",
    "# assumptions about practical (not theoretical, see discrapancy in PCR!) parameters of tests\n",
    "# TODO - but particular data and references from lit (or estimates based on previous similar tests)\n",
    "\n",
    "# TODO - MANUAL! - this function is VERY specific to current health state setup, and needs to be manually edited if number of health states change\n",
    "def inpFunc_testSpecifications(\n",
    "    PCR_FNR_I1_to_R2 = np.array([ 0.9,  0.4, 0.15, 0.35, 0.5, 0.8]),\n",
    "    PCR_FPR = 0.01,\n",
    "    antigen_FNR_I1_to_R2 = np.array([ 0.95, 0.6, 0.35, 0.45, 0.6, 0.9]),\n",
    "    antigen_FPR = 0.1,\n",
    "    antibody_FNR_I1_to_R2 = np.array([0.99, 0.85, 0.8, 0.65, 0.3, 0.05]),\n",
    "    antibody_FPR_S_to_I4 =  np.array([0.05, 0.04, 0.03, 0.02, 0.01])\n",
    "    ):\n",
    "    \n",
    "    \n",
    "    testSpecifications = pd.DataFrame(\n",
    "    columns=[\"Name\"],#, \"Infection stage\"],#, \"Sensitivity\", \"Specificity\"],\n",
    "    \n",
    "    data = (\n",
    "        [\"PCR\"] * nHS +\n",
    "        [\"Antigen\"] * (nHS) +\n",
    "        [\"Antibody\"] * (nHS))\n",
    "    )\n",
    "\n",
    "    testSpecifications['OutputTestState'] = [1]*nHS + [1]*nHS + [2]*nHS # what information state does a pos test transition you to.\n",
    "\n",
    "    testSpecifications['TruePosHealthState'] = [np.arange(1,nI+1)]*nHS + [np.arange(1,nI+1)]*nHS + [np.arange(nI+1,nI+nR+1)]*nHS # what information state does a pos test transition you to.\n",
    "\n",
    "    # In some health states some people are true negatives and some are true positives! (No, makes litte sense to use, just account for it in FPR? Only matters for test makers...)\n",
    "    # testSpecifications['AmbiguousPosHealthState'] = [np.arange(nI+1, nI+nR+1)]*nHS + [np.arange(nI+1, nI+nR+1)]*nHS + [np.arange(1, nI+1)]*nHS # what information state does a pos test transition you to.\n",
    "\n",
    "    testSpecifications['InputHealthState'] = list(np.tile(range(nHS),3))\n",
    "\n",
    "    # These numbers below are \"defaults\" illustrating the concept, but are modified by the inputs!!!\n",
    "    \n",
    "    testSpecifications['FalseNegativeRate'] = [ # ratio of positive (infected / immune) people missed by the test\n",
    "        # For each health stage:\n",
    "        #  S -> I1 (asymp) -> I2 (mild symp) -> I3 (symp, sick) -> I4 (symp, less sick) -> R1 / R2 (IgM, IgG avail) -> D\n",
    "\n",
    "        # PCR\n",
    "            0.,   0.9,            0.4,           0.15,                0.35,              0.5, 0.8,   0.,\n",
    "\n",
    "        # Antigen\n",
    "            0.,   0.95,           0.6,           0.35,                0.45,              0.6, 0.9,   0.,\n",
    "\n",
    "        # Antibody\n",
    "            0.,   0.99,           0.85,          0.8,                 0.65,              0.3, 0.05,  0.\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    testSpecifications.loc[1:6,'FalseNegativeRate'] = PCR_FNR_I1_to_R2\n",
    "    testSpecifications.loc[9:14,'FalseNegativeRate'] = antigen_FNR_I1_to_R2\n",
    "    testSpecifications.loc[17:22,'FalseNegativeRate'] = antibody_FNR_I1_to_R2\n",
    "    \n",
    "    \n",
    "\n",
    "    testSpecifications['FalsePositiveRate'] = [ # ratio of negative (non-infected or not immune) people deemed positive by the test\n",
    "        # PCR\n",
    "        0.01, 0.,0.,0.,0., 0.01, 0.01, 0.,\n",
    "\n",
    "        # Antigen\n",
    "        0.1, 0.,0.,0.,0., 0.1, 0.1, 0.,\n",
    "\n",
    "        # Antibody\n",
    "        0.05, 0.04, 0.03, 0.02, 0.01, 0., 0., 0.        \n",
    "    ]\n",
    "    \n",
    "    testSpecifications.loc[0,'FalsePositiveRate'] = PCR_FPR\n",
    "    testSpecifications.loc[5:6,'FalsePositiveRate'] = PCR_FPR\n",
    "    testSpecifications.loc[8,'FalsePositiveRate'] = antigen_FPR\n",
    "    testSpecifications.loc[13:14,'FalsePositiveRate'] = antigen_FPR\n",
    "    testSpecifications.loc[16:20,'FalsePositiveRate'] = antibody_FPR_S_to_I4\n",
    "    \n",
    "    return testSpecifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpFunc_testSpecifications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - think if we should introdce an \"autopsy test\" posthumously, categorising people as tested after death? \n",
    "# How is this done, is there data on its sens/spec?\n",
    "\n",
    "# Testing capacity\n",
    "# ----------------\n",
    "\n",
    "# Assumptions about the testing capacity available at day d of the simulation \n",
    "\n",
    "# For PCR - we will model this (for now, for fitting we'll plug in real data!), as the sum of two sigmoids:\n",
    "#   - initial stage of PHE ramping up its limited capacity (parameterised by total capacity, inflection day and slope of ramp-up)\n",
    "#   - second stage of non-PHE labs joining in and ramping up capacity (this hasn't happened yet, but expected soon! same parameterisation)\n",
    "\n",
    "# For the antigen / antibody tests we define a single sigmoidal capacity curve (starting later than PCR, but with potentially much higher total capacity)\n",
    "# We further define a ratio between the production of the two, due to them requiring the same capabilities.\n",
    "\n",
    "\n",
    "def trFunc_testCapacity(\n",
    "    realTime, # time within simulation (day)\n",
    "    \n",
    "    # PCR capacity - initial\n",
    "    testCapacity_pcr_phe_total = 1e4,\n",
    "    testCapacity_pcr_phe_inflexday = pd.to_datetime(\"2020-03-25\", format=\"%Y-%m-%d\"),\n",
    "    testCapacity_pcr_phe_inflexslope = 5.,\n",
    "\n",
    "    # PCR capacity - increased\n",
    "    testCapacity_pcr_country_total = 1e5,\n",
    "    testCapacity_pcr_country_inflexday = pd.to_datetime(\"2020-04-25\", format=\"%Y-%m-%d\"),\n",
    "    testCapacity_pcr_country_inflexslope = 10,\n",
    "    \n",
    "    # Antibody / antigen capacity\n",
    "    testCapacity_antibody_country_firstday = pd.to_datetime(\"2020-04-25\", format=\"%Y-%m-%d\"),\n",
    "    \n",
    "    testCapacity_antibody_country_total = 5e6,\n",
    "    testCapacity_antibody_country_inflexday = pd.to_datetime(\"2020-05-20\", format=\"%Y-%m-%d\"),\n",
    "    testCapacity_antibody_country_inflexslope = 20,\n",
    "    \n",
    "    testCapacity_antigenratio_country = 0.7,\n",
    "    \n",
    "    **kwargs\n",
    "             \n",
    "):\n",
    "\n",
    "    # Returns a dictionary with test names and number available at day \"t\"\n",
    "    \n",
    "    outPCR = (\n",
    "        #phe phase\n",
    "        testCapacity_pcr_phe_total * expit((realTime-testCapacity_pcr_phe_inflexday).days/testCapacity_pcr_phe_inflexslope)\n",
    "        +\n",
    "        #whole country phase\n",
    "        testCapacity_pcr_country_total * expit((realTime-testCapacity_pcr_country_inflexday).days/testCapacity_pcr_country_inflexslope)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if realTime<testCapacity_antibody_country_firstday:\n",
    "        outAntiTotal = 0.\n",
    "    else:\n",
    "        outAntiTotal = (\n",
    "            testCapacity_antibody_country_total * expit((realTime-testCapacity_antibody_country_inflexday).days/testCapacity_antibody_country_inflexslope)\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"PCR\": outPCR, \n",
    "        \"Antigen\": outAntiTotal*testCapacity_antigenratio_country, \n",
    "        \"Antibody\": outAntiTotal*(1-testCapacity_antigenratio_country)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Real life data on test capacity and who got tested\n",
    "# ---------------------------------------------------\n",
    "\n",
    "df_CHESS = pd.read_csv(\"/mnt/efs/data/CHESS_Aggregate20200417.csv\").drop(0)\n",
    "df_CHESS.index = pd.to_datetime(df_CHESS[\"DateOfAdmission\"].values,format=\"%d-%m-%Y\")\n",
    "\n",
    "# Ignore too old and too recent data points\n",
    "df_CHESS = df_CHESS.sort_index().drop(\"DateOfAdmission\", axis=1).query('20200309 <= index <= '+CONST_DATA_CUTOFF_DATE)\n",
    "\n",
    "# Get number of tests per age group\n",
    "df_CHESS_numTests = df_CHESS.loc[:,df_CHESS.columns.str.startswith(\"AllAdmittedPatientsTestedForCOVID19\")]\n",
    "\n",
    "# Change age groups to reflect our groupings\n",
    "df_CHESS_numTests_regroup = pd.DataFrame(data = regroup_by_age(\n",
    "    inp = df_CHESS_numTests.to_numpy().T,\n",
    "    fromAgeSplits=np.concatenate([np.array([1,5,15,25]),np.arange(45,85+1,10)]),\n",
    "    toAgeSplits=np.arange(10,80+1,10)\n",
    ").T)\n",
    "\n",
    "df_CHESS_numTests_regroup.index = df_CHESS_numTests.index\n",
    "\n",
    "def inpFunc_testingDataCHESS_PCR(\n",
    "    realTime,\n",
    "    realTestData = df_CHESS_numTests_regroup,\n",
    "    **kwargs\n",
    "    ):\n",
    "    \n",
    "    def nearest(items, pivot):\n",
    "        return min(items, key=lambda x: abs(x - pivot))\n",
    "    \n",
    "    \n",
    "    return df_CHESS_numTests_regroup.loc[nearest(df_CHESS_numTests_regroup.index, pd.to_datetime(realTime, format=\"%Y-%m-%d\"))]\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHESS_numTests_regroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symptom parameters\n",
    "# ------------------\n",
    "\n",
    "\n",
    "# Estimating the baseline ILI-symptoms from earlier studies as well as the success rate of COVID-19 tests\n",
    "\n",
    "# ILI rate estimate from 2018-19 PHE Surveillance of influenza and other respiratory viruses in the UK report: \n",
    "# https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/839350/Surveillance_of_influenza_and_other_respiratory_viruses_in_the_UK_2018_to_2019-FINAL.pdf\n",
    "\n",
    "# TODO - get actual seasonal symptom rate predictions (from 2020 non-SARS respiratory viruses, this data surely exists)\n",
    " # (daily rate estimate from Figure 8 of the report)\n",
    "\n",
    "\n",
    "# Respiratory diagnosis on hospital admissions (not just ILI, all, TODO - get only ILI?)\n",
    "# NHS Hosp episode statistics 2018-19, page 12 https://files.digital.nhs.uk/F2/E70669/hosp-epis-stat-admi-summ-rep-2018-19-rep.pdf\n",
    "# In hospital: 1.1 million respiratory episodes out of 17.1 million total episodes\n",
    "\n",
    "def f_symptoms_nonCOVID(\n",
    "    realTime, \n",
    "    symptomsIliRCGP = 15./100000., # Symptom rate in general non-hospitalised population\n",
    "    symptomsRespInHospitalFAEs = 1.1/17.1, # Symptom rate in hospitalised population\n",
    "    \n",
    "    **kwargs):\n",
    "    \"\"\"\n",
    "    This function defines the non-COVID ILI symptoms rate in the population at a given t time\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # TODO, add extra data etc as input. For now: \n",
    "    return (symptomsIliRCGP, symptomsRespInHospitalFAEs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute tests amongst (a given subset of) symptomatic people\n",
    "def distTestsSymp(people, testsAvailable, noncovid_sympRatio, symp_HS = range(3,5), alreadyTestedRate = None):\n",
    "    \"\"\"\n",
    "    distribute tests amongst symptomatic people\n",
    "    people is nAge x nHS-1 x ... (excluding dead)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate noncovid, but symptomatic people\n",
    "    peopleSymp = copy.deepcopy(people)\n",
    "    peopleSymp[:, :min(symp_HS)] *= noncovid_sympRatio\n",
    "    peopleSymp[:, max(symp_HS):] *= noncovid_sympRatio\n",
    "\n",
    "    # Subtract already tested people\n",
    "    if alreadyTestedRate is not None:\n",
    "        peopleSymp -= people*alreadyTestedRate \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Check if we already tested everyone with a different test\n",
    "    if np.sum(peopleSymp)<1e-6:  # avoid numerical instabilities\n",
    "        return (0.,0.)\n",
    "\n",
    "    testedRatio = min(1., testsAvailable/np.sum(peopleSymp))\n",
    "\n",
    "\n",
    "    return (\n",
    "        # test rate\n",
    "        testedRatio * (peopleSymp/(people+1e-6)), # avoid dividing by zero\n",
    "        # tests used to achieve this\n",
    "        testedRatio * np.sum(peopleSymp)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing policies (how to distribute available tests)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Estimate at any one time how many people are getting tested (with which tests) from which health states\n",
    "def policyFunc_testing_symptomaticOnly(\n",
    "    stateTensor,\n",
    "    realTime,\n",
    "\n",
    "    # Test types (names correspoding to testSpecifications)\n",
    "    testTypes, # = [\"PCR\", \"Antigen\", \"Antibody\"],\n",
    "    \n",
    "    # Test Capacity (dict with names above and numbers available on day t)\n",
    "    testsAvailable, # = trFunc_testCapacity(t)\n",
    "    \n",
    "    # OPTIONAL ARGUMENTS (may be different for different policy functions, should come with defaults!)\n",
    "    antibody_testing_policy = \"hospworker_then_random\", \n",
    "    # This has these values (for now), {\"none\", \"hospworker_then_random\", \"virus_positive_only\", \"virus_positive_only_hospworker_first\"}\n",
    "    \n",
    "    # Baseline symptoms\n",
    "    f_symptoms_nonCOVID = f_symptoms_nonCOVID,\n",
    "    \n",
    "    distributeRemainingToRandom = True,\n",
    "    return_testsAvailable_remaining = False,\n",
    "    \n",
    "    **kwargs\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns a rate distribution of available test types over age, health and isolation states \n",
    "    (although age assumed not to matter here)\n",
    "    \"\"\"\n",
    "   \n",
    "    # Output nAge x nHS x nIso x nTest x len(testTypes) tensor\n",
    "    out_testRate = np.zeros(stateTensor.shape+(len(testTypes),))\n",
    "    \n",
    "    # Testing capacity is testsAvailable\n",
    "    \n",
    "    # Get sympom ratio. [0] - general, [1] - hospitalised\n",
    "    cur_noncovid_sympRatio = f_symptoms_nonCOVID(realTime, **kwargs[\"f_symptoms_nonCOVID_params\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # PCR testing\n",
    "    # -----------\n",
    "    \n",
    "    # Hospitalised people get priority over PCR tests \n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,2,0], # hospitalised non-positive people, exclude tested and dead people\n",
    "        testsAvailable = testsAvailable[\"PCR\"],\n",
    "        noncovid_sympRatio = cur_noncovid_sympRatio[1]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,2,0, testTypes.index(\"PCR\")] += testRate\n",
    "    testsAvailable[\"PCR\"] -= testsUsed\n",
    "    \n",
    "    # Prioritise hospital workers next:\n",
    "    # TODO: check if we should do this? In UK policy there was a 15% max for hospital worker testing until ~2 April...\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,3,0], \n",
    "        testsAvailable = testsAvailable[\"PCR\"],\n",
    "        noncovid_sympRatio= cur_noncovid_sympRatio[0]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,3,0, testTypes.index(\"PCR\")] += testRate\n",
    "    testsAvailable[\"PCR\"] -= testsUsed\n",
    "    \n",
    "    # Distribute PCRs left over the other populations\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,:2,0], \n",
    "        testsAvailable = testsAvailable[\"PCR\"],\n",
    "        noncovid_sympRatio= cur_noncovid_sympRatio[0]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,:2,0, testTypes.index(\"PCR\")] += testRate\n",
    "    testsAvailable[\"PCR\"] -= testsUsed\n",
    "    \n",
    "    if distributeRemainingToRandom:\n",
    "        # Distribute PCRs left over the other populations\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,:,0], \n",
    "            testsAvailable = testsAvailable[\"PCR\"],\n",
    "            noncovid_sympRatio= 1.,\n",
    "            alreadyTestedRate= out_testRate[:,:-1,:,0, testTypes.index(\"PCR\")]\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,:,0, testTypes.index(\"PCR\")] += testRate\n",
    "        testsAvailable[\"PCR\"] -= testsUsed\n",
    "    \n",
    "    \n",
    "    # Antigen testing\n",
    "    # ---------------\n",
    "    \n",
    "    # Hospitalised people get priority over PCR tests \n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,2,0], # hospitalised non-positive people, exclude tested and dead people\n",
    "        testsAvailable = testsAvailable[\"Antigen\"],\n",
    "        noncovid_sympRatio= cur_noncovid_sympRatio[1],\n",
    "        alreadyTestedRate=out_testRate[:,:-1,2, 0, testTypes.index(\"PCR\")]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,2,0, testTypes.index(\"Antigen\")] += testRate\n",
    "    testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "    # Prioritise hospital workers next:\n",
    "    # TODO: check if we should do this? In UK policy there was a 15% max for hospital worker testing until ~2 April...\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,3,0],\n",
    "        testsAvailable = testsAvailable[\"Antigen\"],\n",
    "        noncovid_sympRatio= cur_noncovid_sympRatio[0],\n",
    "        alreadyTestedRate=out_testRate[:,:-1,3, 0, testTypes.index(\"PCR\")]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,3,0, testTypes.index(\"Antigen\")] += testRate\n",
    "    testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "    # Distribute Antigen tests left over the other symptomatic people\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,:2,0],\n",
    "        testsAvailable = testsAvailable[\"Antigen\"],\n",
    "        noncovid_sympRatio= cur_noncovid_sympRatio[0],\n",
    "        alreadyTestedRate=out_testRate[:,:-1,:2, 0, testTypes.index(\"PCR\")]\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,:2,0, testTypes.index(\"Antigen\")] += testRate\n",
    "    testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "    if distributeRemainingToRandom:\n",
    "        # Distribute antigen tests left over the other non-symptmatic populations\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,:,0], \n",
    "            testsAvailable = testsAvailable[\"Antigen\"],\n",
    "            noncovid_sympRatio= 1.,\n",
    "            alreadyTestedRate= out_testRate[:,:-1,:,0, :].sum(-1)\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,:,0, testTypes.index(\"Antigen\")] += testRate\n",
    "        testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "    \n",
    "    # Antibody testing\n",
    "    # ----------------\n",
    "    \n",
    "    if antibody_testing_policy == \"hospworker_then_random\":\n",
    "    \n",
    "        # For now: give to hospital workers first, not taking into account previous tests or symptoms\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,3,:2], \n",
    "            testsAvailable = testsAvailable[\"Antibody\"],\n",
    "            noncovid_sympRatio= 1. # basically workers get antibody tested regardless of symptoms\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,3,:2, testTypes.index(\"Antibody\")] += testRate\n",
    "        testsAvailable[\"Antibody\"] -= testsUsed\n",
    "\n",
    "        # Afterwards let's just distribute randomly in the rest of the population\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,:3,:2], \n",
    "            testsAvailable = testsAvailable[\"Antibody\"],\n",
    "            noncovid_sympRatio= 1. # basically people get antibody tested regardless of symptoms\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,:3,:2, testTypes.index(\"Antibody\")] += testRate\n",
    "        testsAvailable[\"Antibody\"] -= testsUsed\n",
    "    \n",
    "    if antibody_testing_policy == \"virus_positive_only_hospworker_first\":\n",
    "        \n",
    "        # For now: give to hospital workers first, not taking into account previous tests or symptoms\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,3,1], \n",
    "            testsAvailable = testsAvailable[\"Antibody\"],\n",
    "            noncovid_sympRatio= 1. # basically workers get antibody tested regardless of symptoms\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,3,1, testTypes.index(\"Antibody\")] += testRate\n",
    "        testsAvailable[\"Antibody\"] -= testsUsed\n",
    "\n",
    "        # Afterwards let's just distribute randomly in the rest of the population\n",
    "        # TODO: Maybe prioratise people who tested positive for the virus before???\n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,:3,1], \n",
    "            testsAvailable = testsAvailable[\"Antibody\"],\n",
    "            noncovid_sympRatio= 1. # basically people get antibody tested regardless of symptoms\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,:3,1, testTypes.index(\"Antibody\")] += testRate\n",
    "        testsAvailable[\"Antibody\"] -= testsUsed\n",
    "        \n",
    "        \n",
    "    if antibody_testing_policy == \"virus_positive_only\":\n",
    "        \n",
    "        testRate, testsUsed = distTestsSymp(\n",
    "            people = stateTensor[:,:-1,:,1], \n",
    "            testsAvailable = testsAvailable[\"Antibody\"],\n",
    "            noncovid_sympRatio= 1. # basically people get antibody tested regardless of symptoms\n",
    "        )\n",
    "\n",
    "        out_testRate[:,:-1,:,1, testTypes.index(\"Antibody\")] += testRate\n",
    "        testsAvailable[\"Antibody\"] -= testsUsed\n",
    "        \n",
    "    if antibody_testing_policy == \"none\":\n",
    "        out_testRate += 0.\n",
    "        testsAvailable[\"Antibody\"] -= 0.\n",
    "    \n",
    "\n",
    "    \n",
    "    if return_testsAvailable_remaining:\n",
    "        return out_testRate, testsAvailable\n",
    "    \n",
    "    return out_testRate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reTesting policy(s) (ie give tests to people in non-0 test states!)\n",
    "def policyFunc_testing_massTesting_with_reTesting(\n",
    "    stateTensor,\n",
    "    realTime,\n",
    "   \n",
    "    # Test types (names correspoding to testSpecifications)\n",
    "    testTypes, # = [\"PCR\", \"Antigen\", \"Antibody\"],\n",
    "    \n",
    "    # Test Capacity (dict with names above and numbers available on day t)\n",
    "    testsAvailable, # = trFunc_testCapacity(t)\n",
    "    \n",
    "    # OPTIONAL ARGUMENTS (may be different for different policy functions, should come with defaults!)\n",
    "    \n",
    "    basic_policyFunc = policyFunc_testing_symptomaticOnly,\n",
    "    # This basic policy will: \n",
    "    # - do PCRs on symptomatic hospitalised people\n",
    "    # - do PCRs on symptomatic hospital staff\n",
    "    # - do PCRs on symptomatic non-hospitalised people\n",
    "    # If PCRs run out at any stage, we use antigen tests with same priorisation\n",
    "    \n",
    "    # Afterwards given fractions of remaining antigen tests are distributed amongst people given these ratios and their earlier testing status:\n",
    "    #retesting_antigen_viruspos_ratio = 0.1, # find virus false positives\n",
    "    # UPDATE <- retesting viruspos is same ratio is normal testing, as long as they're not in quarantine already!\n",
    "    retesting_antigen_immunepos_ratio = 0.05, # find immunity false positives\n",
    "    # The rest of antigen tests are given out randomly\n",
    "    \n",
    "    # Antibody tests are used primarily on people who tested positive for the virus \n",
    "    #  (set in basic_policyFunc!, use \"virus_positive_only_hospworker_first\"!)\n",
    "    # Afterwards we can use the remaining on either random people (dangerous with many false positives!) \n",
    "    # or for retesting people with already positive immune tests to make sure they're still immune,\n",
    "    # controlled by this ratio:\n",
    "    retesting_antibody_immunepos_ratio = 1.,\n",
    "    \n",
    "    #distributeRemainingToRandom = True, # TODO - otherwise stockpile for future, how?\n",
    "    return_testsAvailable_remaining = False,   \n",
    "    \n",
    "    **kwargs\n",
    "    ):\n",
    "    \n",
    "    # Output nAge x nHS x nIso x nTest x len(testTypes) tensor\n",
    "    out_testRate = np.zeros(stateTensor.shape+(len(testTypes),))\n",
    "    \n",
    "    \n",
    "    # First distribute tests to symptomatic people as usual:\n",
    "\n",
    "    # inpArgs change to not distributing tests randomly:\n",
    "    basic_policyFunc_params_modified = copy.deepcopy(kwargs[\"basic_policyFunc_params\"])\n",
    "    basic_policyFunc_params_modified[\"distributeRemainingToRandom\"] = False\n",
    "    basic_policyFunc_params_modified[\"return_testsAvailable_remaining\"] = True\n",
    "    \n",
    "    \n",
    "    # Run the basic policy function with these modified parameters\n",
    "    out_testRate, testsAvailable = basic_policyFunc(\n",
    "        stateTensor,\n",
    "        realTime = realTime,\n",
    "        testTypes = testTypes,\n",
    "        testsAvailable = testsAvailable,\n",
    "        **basic_policyFunc_params_modified\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # We assume PCRs tend to run out done on symptomatic people in 0 Test state, so no retesting via PCR.\n",
    "    \n",
    "    \n",
    "    # Antigen testing\n",
    "    # ---------------\n",
    "       \n",
    "    # Retesting immune positive people\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,:,2:], # immune positive people\n",
    "        testsAvailable = testsAvailable[\"Antigen\"] * retesting_antigen_immunepos_ratio,\n",
    "        noncovid_sympRatio= 1., # set to 1. for ignoring symptom vs non-symptom\n",
    "    )\n",
    "    \n",
    "    out_testRate[:,:-1,:,2:, testTypes.index(\"Antigen\")] += testRate\n",
    "    testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "\n",
    "    # Distribute antigen tests left over the other non-symptmatic populations\n",
    "    # UPDATE <- here we use tests equally distributed among people with negative or positive previous virus tests, \n",
    "    # as long as they are in non-quarantined state (isoState 0) # TODO - hospital worker testing???\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,0,:2], # non-quarantined virus positive people\n",
    "        testsAvailable = testsAvailable[\"Antigen\"],\n",
    "        noncovid_sympRatio= 1.,\n",
    "        alreadyTestedRate= out_testRate[:,:-1,0,:2, testTypes.index(\"Antigen\")] + out_testRate[:,:-1,0,:2, testTypes.index(\"PCR\")]\n",
    "    )\n",
    "\n",
    "    out_testRate[:,:-1,0,:2, testTypes.index(\"Antigen\")] += testRate\n",
    "    testsAvailable[\"Antigen\"] -= testsUsed\n",
    "    \n",
    "    \n",
    "    # Antibody testing\n",
    "    # -----------------\n",
    "    # Retesting antibody positive people\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,:,2:], # virus positive people\n",
    "        testsAvailable = testsAvailable[\"Antibody\"] * retesting_antibody_immunepos_ratio,\n",
    "        noncovid_sympRatio= 1., # set to 1. for ignoring symptom vs non-symptom\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Afterwards let's just distribute randomly in the rest of the population\n",
    "    testRate, testsUsed = distTestsSymp(\n",
    "        people = stateTensor[:,:-1,:,:2], \n",
    "        testsAvailable = testsAvailable[\"Antibody\"],\n",
    "        noncovid_sympRatio= 1., # basically people get antibody tested regardless of symptoms\n",
    "        alreadyTestedRate= out_testRate[:,:-1,:,:2, testTypes.index(\"Antibody\")]\n",
    "    )\n",
    "\n",
    "    out_testRate[:,:-1,:,:2, testTypes.index(\"Antibody\")] += testRate\n",
    "    testsAvailable[\"Antibody\"] -= testsUsed\n",
    "    \n",
    "    \n",
    "    if return_testsAvailable_remaining:\n",
    "        return out_testRate, testsAvailable\n",
    "    \n",
    "    return out_testRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trFunc_testing(\n",
    "    stateTensor,\n",
    "    t,\n",
    "    realStartDate,\n",
    "    #policyFunc = policyFunc_testing_symptomaticOnly,\n",
    "    policyFunc = policyFunc_testing_massTesting_with_reTesting,\n",
    "    inpFunc_testSpecifications = inpFunc_testSpecifications, \n",
    "    trFunc_testCapacity = trFunc_testCapacity,\n",
    "    inpFunc_realData_testCapacity = inpFunc_testingDataCHESS_PCR,\n",
    "    **kwargs\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Returns a tensor of rates transitioning to tested states\n",
    "    \"\"\"\n",
    "    trTensor_testTransitions = np.zeros((nAge, nHS, nIso, nTest, nTest))\n",
    "    \n",
    "    \n",
    "    testSpecifications = inpFunc_testSpecifications(**kwargs[\"inpFunc_testSpecifications_params\"])\n",
    "    \n",
    "    testTypes = list(set(testSpecifications[\"Name\"]))\n",
    "    \n",
    "    \n",
    "    # Check if we have real data on the administered tests\n",
    "    \n",
    "    # Add the current data on within-hospital PCRs carried out already\n",
    "    curDate = pd.to_datetime(realStartDate, format=\"%Y-%m-%d\") + pd.to_timedelta(int(t), unit=\"D\")\n",
    "    realData_closest = inpFunc_realData_testCapacity(realTime = curDate, **kwargs[\"inpFunc_realData_testCapacity_params\"])\n",
    "            \n",
    "    if realData_closest.name == curDate: # We do have data, just fill it in\n",
    "        testsAdministeredRate = np.zeros(stateTensor.shape+(len(testTypes),))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # TODO - fix this very hacky solution accessing symptomatic ratio as a subfunc of the policy func\n",
    "        noncovid_sympRatio = kwargs[\"policyFunc_params\"][\"basic_policyFunc_params\"][\"f_symptoms_nonCOVID\"](curDate, **kwargs[\"policyFunc_params\"][\"basic_policyFunc_params\"][\"f_symptoms_nonCOVID_params\"])\n",
    "        noncovid_sympRatio = noncovid_sympRatio[1] # Use hospitalised patient symptom ratio\n",
    "        symptomaticRatePerDiseaseState = np.array([noncovid_sympRatio]*stateTensor.shape[1])\n",
    "        symptomaticRatePerDiseaseState[3:-(nR+1)] = 1. # set the symptomatic ratio of symptomatic states to 1\n",
    "        symptomaticPeoplePerDiseaseStateInHospital = stateTensor[:,:-1, 2, 0] * np.expand_dims(symptomaticRatePerDiseaseState[:-1], axis=0)\n",
    "        \n",
    "        testsAdministeredRate[:,:-1, 2, 0, testTypes.index(\"PCR\")] += (\n",
    "            np.expand_dims(realData_closest.to_numpy(),1) # true number of tests on given day per age group\n",
    "            * \n",
    "            (symptomaticPeoplePerDiseaseStateInHospital / np.sum(symptomaticPeoplePerDiseaseStateInHospital, axis=-1, keepdims=True)) \n",
    "            # Calculate in what ratio we distribute the tests to people along disease states based on symptomatic (age is given in data!)\n",
    "        )/(stateTensor[:,:-1, 2, 0]+1e-10) # Divide by total people in each state to get testing rate\n",
    "\n",
    "        \n",
    "    \n",
    "    else: # we don't have data, follow our assumed availability and policy curves\n",
    "        \n",
    "        # policyFunc returns stateTensor x testTypes tensor of test administration rates \n",
    "        testsAdministeredRate = policyFunc(\n",
    "            stateTensor,\n",
    "            realTime = curDate,\n",
    "            testTypes = testTypes,\n",
    "            testsAvailable = trFunc_testCapacity(realTime = curDate, **kwargs[\"trFunc_testCapacity_params\"]),\n",
    "            **kwargs[\"policyFunc_params\"]\n",
    "        )\n",
    "       \n",
    "    \n",
    "    \n",
    "    # Compute the transition ratio to tested states, given the administered tests\n",
    "        \n",
    "    for testType in testTypes:\n",
    "        # Get the appropriate slices from testsAdmin. and testSpecs\n",
    "        curTestSpecs = testSpecifications[testSpecifications[\"Name\"]==testType]\n",
    "\n",
    "        for curTS in range(nTest): \n",
    "            # Set output positive test state based on current test state\n",
    "            if curTS == int(curTestSpecs[\"OutputTestState\"].values[0]):\n",
    "                # already positive for the given test\n",
    "                outTS_pos = curTS\n",
    "            elif curTS == 3:\n",
    "                # If already positive for both, stay positive\n",
    "                outTS_pos = 3\n",
    "            else:\n",
    "                # Transition 0->1, 0->2, 1->2, 1->3 or 2->3\n",
    "                outTS_pos = curTS + int(curTestSpecs[\"OutputTestState\"].values[0])\n",
    "                    \n",
    "            \n",
    "            # Where do we go after negative test based on where we are now?\n",
    "            if curTS == 0:\n",
    "                # Negatives stay negatives\n",
    "                outTS_neg = 0\n",
    "            elif curTS == 3: \n",
    "                # go to only virus or antibody positive from both positive\n",
    "                outTS_neg = 3-int(curTestSpecs[\"OutputTestState\"].values[0])\n",
    "            elif curTS == int(curTestSpecs[\"OutputTestState\"].values[0]):\n",
    "                # go to 0 if tested for the one you're positive for\n",
    "                outTS_neg = 0\n",
    "            else:\n",
    "                # stay where you are if you test negative for the one you didnt have anyway\n",
    "                outTS_neg = curTS\n",
    "                \n",
    "            \n",
    "            \n",
    "            # Get the transition rates based on current health states\n",
    "            for curHS in range(nHS):\n",
    "                # Add the true positives * (1-FNR)\n",
    "                if curHS in curTestSpecs[\"TruePosHealthState\"].values[0]:\n",
    "                    trTensor_testTransitions[:,curHS,:, curTS, outTS_pos] += (                        \n",
    "                        testsAdministeredRate[:,curHS,:,curTS,testTypes.index(testType)] *\n",
    "                        (1-curTestSpecs[curTestSpecs[\"InputHealthState\"] == curHS][\"FalseNegativeRate\"].values[0])\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                # Add the false positives * FPR\n",
    "                    trTensor_testTransitions[:,curHS,:,curTS, outTS_pos] += (                        \n",
    "                        testsAdministeredRate[:,curHS,:,curTS,testTypes.index(testType)] *\n",
    "                        curTestSpecs[curTestSpecs[\"InputHealthState\"] == curHS][\"FalsePositiveRate\"].values[0]\n",
    "                    )\n",
    "\n",
    "\n",
    "                # Add the false negatives (FNR)\n",
    "                if curHS in curTestSpecs[\"TruePosHealthState\"].values[0]:\n",
    "                    trTensor_testTransitions[:,curHS,:,curTS,outTS_neg] += (                        \n",
    "                        testsAdministeredRate[:,curHS,:,curTS,testTypes.index(testType)] *\n",
    "                        curTestSpecs[curTestSpecs[\"InputHealthState\"] == curHS][\"FalseNegativeRate\"].values[0]\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                # Add the true negatives * (1-FNR)\n",
    "                    trTensor_testTransitions[:,curHS,:,curTS,outTS_neg] += (                        \n",
    "                        testsAdministeredRate[:,curHS,:,curTS,testTypes.index(testType)] *\n",
    "                        curTestSpecs[curTestSpecs[\"InputHealthState\"] == curHS][\"FalsePositiveRate\"].values[0]\n",
    "                    )\n",
    "                \n",
    "    \n",
    "\n",
    "    return trTensor_testTransitions#, testsAdministeredRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarantine policies\n",
    "\n",
    "This section describes alternatives to the social distancing by full lockdown (that is implemented as a change in the socialMixing matrices).\n",
    "\n",
    "One alternative is case isolation, either by hospitalisation or by home isolation. We will assume that all non-symptomatic people who test positive are home isolated along with families for nDaysInIsolation days. Symptomatic people have a chance of being immediately hospitalised instead of sent into home isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trFunc_quarantine_caseIsolation(\n",
    "    trTensor_complete,\n",
    "    t,\n",
    "    trTensor_testing, # This is used to establish who gets tests and how many of those end up positive.\n",
    "    nDaysInHomeIsolation = 14.,\n",
    "    timeToIsolation = 0.5, # (days) time from testing positive to actually getting isolated\n",
    "    # On average this many people get hospitalised (compared to home isolation), but modulated by age (TODO: values > 1? clip for now..)\n",
    "    symptomHospitalisedRate_ageAdjusted = np.clip(\n",
    "        adjustRatesByAge_KeepAverageRate(0.3, ageRelativeAdjustment=relativeAdmissionRisk_given_COVID_by_age),\n",
    "        0.,1.),\n",
    "    symptomaticHealthStates = [3,4], # TODO - define this in global variable and just pass here!\n",
    "    **kwargs\n",
    "    ):\n",
    "    \"\"\"\n",
    "    This function redistributes testing rates, so they dont only create a testing state update, but also an isolation state update\n",
    "    \"\"\"\n",
    "\n",
    "    trTensor_quarantineRate = np.zeros(stateTensor.shape+(nIso,))\n",
    "    \n",
    "    trTensor_freshlyVirusPositiveRate_inIso0 = copy.deepcopy(trTensor_testing[:,:,0,:2,1])\n",
    "    trTensor_freshlyBothPositiveRate_inIso0 = copy.deepcopy(trTensor_testing[:,:,0,2:,3])\n",
    "    \n",
    "    \n",
    "    for curHS in range(stateTensor.shape[1]-1): # ignore dead\n",
    "        if curHS in symptomaticHealthStates:\n",
    "            # Send a fraction of people (normal) who are symptomatic and tested positive to hospital, based on their age\n",
    "            trTensor_quarantineRate[:,curHS,0,:2,2] += (\n",
    "                (1./timeToIsolation)*symptomHospitalisedRate_ageAdjusted[:,np.newaxis]\n",
    "                *\n",
    "                trTensor_freshlyVirusPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "            trTensor_quarantineRate[:,curHS,0,2:,2] += (\n",
    "                (1./timeToIsolation)*symptomHospitalisedRate_ageAdjusted[:,np.newaxis]\n",
    "                *\n",
    "                trTensor_freshlyBothPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "            # The rest to home isolation\n",
    "            trTensor_quarantineRate[:,curHS,0,:2,1] += (\n",
    "                (1./timeToIsolation)*(1.-symptomHospitalisedRate_ageAdjusted[:,np.newaxis])\n",
    "                *\n",
    "                trTensor_freshlyVirusPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "            trTensor_quarantineRate[:,curHS,0,2:,1] += (\n",
    "                (1./timeToIsolation)*(1.-symptomHospitalisedRate_ageAdjusted[:,np.newaxis])\n",
    "                *\n",
    "                trTensor_freshlyBothPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Send all non-symptomatic (normal) who tested freshly positive to home isolation\n",
    "            trTensor_quarantineRate[:,curHS,0,:2,1] += (\n",
    "                1./timeToIsolation\n",
    "                *\n",
    "                trTensor_freshlyVirusPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "            trTensor_quarantineRate[:,curHS,0,2:,1] += (\n",
    "                1./timeToIsolation\n",
    "                *\n",
    "                trTensor_freshlyBothPositiveRate_inIso0[:,curHS]\n",
    "            )\n",
    "    \n",
    "    # Release people from home isolation after isolation period\n",
    "    trTensor_quarantineRate[:,:,1,:,0] = 1./nDaysInHomeIsolation\n",
    "    \n",
    "    # Hospitalised people are assumed to be released after recovery, with normal rates (TODO: think if this is correct)\n",
    "    \n",
    "    # TODO!!! - importantly, hospital workers are not being home isolated / hospitalised under this policy. \n",
    "    # How to keep track of hospital workers who get hospitalised or home isolated themselves, \n",
    "    # such that they get back to being hospital workers afterwards? \n",
    "    # A simple (slightly incorrect) solution would be to just implement a non-specific \"pull\" from isoState=0 people to hospital workers to fill up the missing people?\n",
    "    # But the rate of this pull would be impossible to compute and would still be incorrect. Gotta think more on this.\n",
    "    \n",
    "    \n",
    "    # Update the whole tensor accordingly\n",
    "    # Make a copy for safety:\n",
    "    out_trTensor_complete = copy.deepcopy(trTensor_complete)\n",
    "    \n",
    "    # First remove all the iso 0->0, test 0,1->1, 2,3->3 transitions (as they're all either hospitalised or sent to home isolation)\n",
    "    out_trTensor_complete[:,:,0,:2,:,0,1] = 0.\n",
    "    out_trTensor_complete[:,:,0,2:,:,0,3] = 0.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Newly virus positive, newly home-isolated, diagonal in disease state transition\n",
    "    np.einsum('ijkj->ijk',\n",
    "        out_trTensor_complete[:,:,0,:2,:,1,1])[:] = trTensor_quarantineRate[:,:,0,:2,1]\n",
    "    np.einsum('ijkj->ijk',\n",
    "        out_trTensor_complete[:,:,0,2:,:,1,3])[:] = trTensor_quarantineRate[:,:,0,2:,1]\n",
    "    \n",
    "    # Newly virus positive, newly hospitalised, diagonal in disease state transition\n",
    "    np.einsum('ijkj->ijk',\n",
    "        out_trTensor_complete[:,:,0,:2,:,2,1])[:] = trTensor_quarantineRate[:,:,0,:2,2]\n",
    "    np.einsum('ijkj->ijk',\n",
    "        out_trTensor_complete[:,:,0,2:,:,2,3])[:] = trTensor_quarantineRate[:,:,0,2:,2]\n",
    "    \n",
    "    # Home isolated people are \"let go\" after nDaysInHomeIsolation, without changing disease or testing state\n",
    "    # (TODO: represent multiple testing / needing negative tests to let go, etc - hard problem!)\n",
    "    # (UPDATE: multiple testing have now been represented, but for now we'll still let go people based on fixed time rather than negative test, to save tests!)\n",
    "    np.einsum('ijkjk->ijk',\n",
    "        out_trTensor_complete[:,:,1,:,:,0,:])[:] = trTensor_quarantineRate[:,:,1,:,0]\n",
    "    \n",
    "    \n",
    "    # Return the full updated tensor (so NOT += outside, but actually =)\n",
    "    return out_trTensor_complete\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes the right side of the non-lin model ODE\n",
    "def dydt_Complete(t, \n",
    "                  stateTensor_flattened, # Might be double the normal size (as first dimension) _withNewOnlyCopy, if debugReturnNewPerDay\n",
    "                  \n",
    "                  realStartDate = pd.to_datetime(\"2020-02-20\", format=\"%Y-%m-%d\"),\n",
    "                  \n",
    "                  # debug\n",
    "                  debugTransition = False,\n",
    "                  debugTimestep = False,\n",
    "                  debugReturnNewPerDay = True, # Now implemented by default into state iteration\n",
    "                  \n",
    "                  # Dimensions\n",
    "                  nAge=nAge, nHS=nHS, nI=nI, nR=nR, nIso=nIso, nTest=nTest,\n",
    "                  \n",
    "                  # Input functions and tensors\n",
    "                  # ----------------------------\n",
    "                  \n",
    "                  # Health state updates\n",
    "                  trFunc_diseaseProgression = trFunc_diseaseProgression,\n",
    "                  trFunc_newInfections = trFunc_newInfections_Complete,\n",
    "                  \n",
    "                  # Initial incoming travel-based infections (before restrictions)\n",
    "                  trFunc_travelInfectionRate_ageAdjusted = trFunc_travelInfectionRate_ageAdjusted,\n",
    "                  \n",
    "                  # Hospitalisation and recovery\n",
    "                  trFunc_HospitalAdmission = trFunc_HospitalAdmission,\n",
    "                  trFunc_HospitalDischarge = trFunc_HospitalDischarge,                  \n",
    "                  \n",
    "                  # Policy changes (on social distancing for now) (TODO - possibly make more changes)\n",
    "                  tStartSocialDistancing = pd.to_datetime(\"2020-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  tStopSocialDistancing = pd.to_datetime(\"2025-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  \n",
    "                  tStartImmunityPassports = pd.to_datetime(\"2025-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  tStopImmunityPassports = pd.to_datetime(\"2025-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  \n",
    "                  tStartQuarantineCaseIsolation = pd.to_datetime(\"2025-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  tStopQuarantineCaseIsolation = pd.to_datetime(\"2025-03-23\", format=\"%Y-%m-%d\"),\n",
    "                  trFunc_quarantine = trFunc_quarantine_caseIsolation,\n",
    "                  \n",
    "                  # Testing\n",
    "                  trFunc_testing = trFunc_testing,\n",
    "                  #policyFunc_testing = policyFunc_testing_symptomaticOnly,\n",
    "                  #testSpecifications = testSpecifications, \n",
    "                  #trFunc_testCapacity = trFunc_testCapacity,\n",
    "                  #trFunc_testCapacity_param_testCapacity_antigenratio_country = 0.3\n",
    "                  \n",
    "                  **kwargs\n",
    "                  \n",
    "):\n",
    "    \n",
    "    if debugTimestep:\n",
    "        print(t)\n",
    "    \n",
    "    # Initialise return\n",
    "    if debugReturnNewPerDay: # the input has 2 copies of the state tensor, second copy being the cumulative incomings\n",
    "        stateTensor = np.reshape(stateTensor_flattened, [2, nAge, nHS, nIso, nTest])[0]\n",
    "    else:\n",
    "        stateTensor = np.reshape(stateTensor_flattened, [nAge, nHS, nIso, nTest])\n",
    "    \n",
    "    dydt = np.zeros_like(stateTensor)\n",
    "    \n",
    "    # Initialise the full transition tensor\n",
    "    trTensor_complete = np.zeros((nAge, nHS, nIso, nTest, nHS, nIso, nTest))\n",
    "    \n",
    "\n",
    "    # Disease condition updates\n",
    "    # ---------------------------\n",
    "    trTensor_diseaseProgression = trFunc_diseaseProgression(**kwargs[\"trFunc_diseaseProgression_params\"])\n",
    "    \n",
    "    # Get disease condition updates with no isolation or test transition (\"diagonal along those\")\n",
    "    for k1 in [0,1,2,3]:\n",
    "        np.einsum('ijlml->ijlm',\n",
    "            trTensor_complete[:,:,k1,:,:,k1,:])[:] += np.expand_dims(\n",
    "                trTensor_diseaseProgression[:,:,k1,:]\n",
    "                ,[2]) # all non-hospitalised disease progression is same\n",
    "\n",
    "  \n",
    "    # Compute new infections (0->1 in HS) with no isolation or test transition (\"diagonal along those\")\n",
    "    cur_policySocialDistancing = (\n",
    "                    t >= (tStartSocialDistancing - realStartDate).days\n",
    "                )*(\n",
    "                    t <   (tStopSocialDistancing - realStartDate).days\n",
    "                )\n",
    "    cur_policyImmunityPassports = (\n",
    "                    t >= (tStartImmunityPassports - realStartDate).days\n",
    "                )*(\n",
    "                    t <   (tStopImmunityPassports - realStartDate).days\n",
    "                )\n",
    "    np.einsum('iklkl->ikl',\n",
    "        trTensor_complete[:,0,:,:,1,:,:])[:] += (\n",
    "            trFunc_newInfections(\n",
    "                stateTensor, \n",
    "                policySocialDistancing = cur_policySocialDistancing,\n",
    "                policyImmunityPassports = cur_policyImmunityPassports,\n",
    "                **kwargs[\"trFunc_newInfections_params\"]\n",
    "            ))\n",
    "    \n",
    "    # Also add new infected from travelling of healthy people, based on time-within-simulation (this is correct with all (0,0) states, as tested or isolated people dont travel)\n",
    "    trTensor_complete[:,0,0,0,1,0,0] += trFunc_travelInfectionRate_ageAdjusted(t, **kwargs[\"trFunc_travelInfectionRate_ageAdjusted_params\"])\n",
    "    \n",
    "    \n",
    "    # Hospitalisation state updates\n",
    "    # -----------------------\n",
    "    \n",
    "    # Hospitalisation and recovery rates\n",
    "    # We assume for now that these only depend on age and disease progression, not on testing state \n",
    "    # (TODO - update this given new policies)\n",
    "    \n",
    "    # The disease and testing states don't change due to hospitalisation. \n",
    "    # Hospital staff is treated as already hospitalised from all aspects expect social mixing, should suffice for now\n",
    "    # TODO - Could try to devise a scheme in which hospital staff gets hospitalised and some recoveries from hospitalised state go back to hospital staff.\n",
    "    # TODO - same issue with hospital staff home isolating; that's probably more important question!\n",
    "    for k1 in [0,1]:\n",
    "         np.einsum('ijljl->ijl',\n",
    "            trTensor_complete[:,:,k1,:,:,2,:])[:] += np.expand_dims(\n",
    "             trFunc_HospitalAdmission(**kwargs[\"trFunc_HospitalAdmission_params\"]),[2])   \n",
    "\n",
    "    # Add recovery from hospital rates\n",
    "    # TODO - again here (for now) we assume all discharged people go back to \"normal state\" instead of home isolation, have to think more on this\n",
    "    np.einsum('ijljl->ijl',\n",
    "            trTensor_complete[:,:,2,:,:,0,:])[:] += np.expand_dims(\n",
    "                 trFunc_HospitalDischarge(**kwargs[\"trFunc_HospitalDischarge_params\"]),[2])     \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Testing state updates\n",
    "    # ---------------------\n",
    "    \n",
    "    # trFunc_testing returns a stateTensor x testStates output \n",
    "    #      after the policyFunc assigns tests that are evaluated according to testSpecifications\n",
    "    \n",
    "    # Diagonal (no transitions) in age, health state and isolation state \n",
    "    # (for now, probably TODO: testing positive correlates with new hospitalisation!)\n",
    "    trTensor_testing = trFunc_testing(\n",
    "                                            stateTensor,\n",
    "                                            t,\n",
    "                                            realStartDate,\n",
    "                                            **kwargs[\"trFunc_testing_params\"]\n",
    "                                        )  \n",
    "    \n",
    "    np.einsum('ijkljkm->ijklm',\n",
    "            trTensor_complete)[:] += trTensor_testing\n",
    "\n",
    "    \n",
    "    # Quarantine policy\n",
    "    # ------------------\n",
    "    \n",
    "    # Check if policy is \"on\"\n",
    "    if (\n",
    "            t >= (tStartQuarantineCaseIsolation - realStartDate).days\n",
    "        )*(\n",
    "            t <   (tStopQuarantineCaseIsolation - realStartDate).days\n",
    "        ):\n",
    "        # New quarantining only happens to people who are transitioning already from untested to virus positive state\n",
    "        # Therefore here we DO use non-diagonal transitions, and we \n",
    "        #     redistribute the transtion rates given the testing (which was previously assumed not to create transition in isolation state)\n",
    "        trTensor_complete = trFunc_quarantine(\n",
    "                                                trTensor_complete,\n",
    "                                                t,\n",
    "                                                trTensor_testing, \n",
    "                                                **kwargs[\"trFunc_quarantine_params\"]\n",
    "                                            )\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    # Final corrections\n",
    "    # -----------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO: simulate aging and normal birth / death (not terribly important on these time scales, but should be quite simple)\n",
    "    \n",
    "    \n",
    "    # Ensure that every \"row\" sums to 0 by adding to the diagonal (doesn't create new people out of nowhere)\n",
    "    # Extract (writable) diagonal array and subtract the \"row\"-sums for each initial state\n",
    "    np.einsum('ijkljkl->ijkl', trTensor_complete)[:] -= np.einsum('...jkl->...', trTensor_complete) \n",
    "    \n",
    "    \n",
    "    # Compute the actual derivatives\n",
    "    dydt = np.einsum('ijkl,ijklmnp->imnp', stateTensor, trTensor_complete) # contract the HS axis, keep age\n",
    "    \n",
    "    \n",
    "    if debugReturnNewPerDay:\n",
    "        \"\"\"\n",
    "            If this is true, instead of returning the real dydt, \n",
    "            return only the positive \"incoming\" number of people to each state, so we can track \"new cases\"\n",
    "            This needs some approximations, as follows:\n",
    "                1. Take the normal transition tensor (with rates potentially > 0)\n",
    "                2. From all states re-normalise the outgoing rates to sum at most to 1 \n",
    "                    (if they were less, keep it, if larger, then this represents \n",
    "                    in this day, all people will leave this state, in these ratios to these states)\n",
    "                3. Multiply only these outgoing rates with the current state \n",
    "                    (so the result wont keep the same number of people as normal, \n",
    "                    but only represent the new incomings for each state)\n",
    "        \"\"\"\n",
    "        \n",
    "        trTensor_complete_newOnly = copy.deepcopy(trTensor_complete)\n",
    "        \n",
    "        # TODO - Think - this is probably unnecessary actually, artifically reduces \"new\" rates?\n",
    "#         # Devide each row by the absolute diagonal rate (that is the sum of the row), but only if its larger than 1\n",
    "#         trTensor_complete_newOnly /= (\n",
    "#             np.expand_dims(\n",
    "#                 np.clip(np.abs(np.einsum('ijkljkl->ijkl', trTensor_complete_newOnly)), a_min=1., a_max=np.inf),\n",
    "#                 axis=[4,5,6]\n",
    "#             )\n",
    "#         )\n",
    "        \n",
    "        # Set the diagonals to zero (no preservation, no outgoing, will end up being the incoming only)\n",
    "        np.einsum('ijkljkl->ijkl', trTensor_complete_newOnly)[:] = 0.\n",
    "        \n",
    "        dydt_newOnly = np.einsum('ijkl,ijklmnp->imnp', stateTensor, trTensor_complete_newOnly)\n",
    "        \n",
    "        dydt = np.stack([dydt, dydt_newOnly], axis=0)\n",
    "    \n",
    "    \n",
    "    if debugTransition:\n",
    "        return np.reshape(dydt, -1), trTensor_complete\n",
    "    \n",
    "    return np.reshape(dydt, -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise state\n",
    "stateTensor_init = copy.deepcopy(stateTensor)\n",
    "\n",
    "# Populate \n",
    "stateTensor_init[:,0,0,0] = agePopulationTotal\n",
    "\n",
    "# Move hospital staff to working in hospital\n",
    "stateTensor_init[:,0,0,0] -= ageNhsClinicalStaffPopulationRatio * agePopulationTotal\n",
    "stateTensor_init[:,0,3,0] += ageNhsClinicalStaffPopulationRatio * agePopulationTotal\n",
    "\n",
    "# Move people to hospital according to baseline occupation (move only from normal people, not hospital staff!)\n",
    "stateTensor_init[:,0,2,0] += initBaselineHospitalOccupancyEquilibriumAgeRatio * stateTensor_init[:,0,0,0]\n",
    "stateTensor_init[:,0,0,0] -= initBaselineHospitalOccupancyEquilibriumAgeRatio * stateTensor_init[:,0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Infect some young adults/middle-aged people\n",
    "# stateTensor_init[2:4,0,0,0] -= 1000.#/np.sum(agePopulationTotal)\n",
    "# stateTensor_init[2:4,1,0,0] += 1000.#/np.sum(agePopulationTotal)\n",
    "\n",
    "# BETTER! - People get infected by travel in early stages!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveSystem(stateTensor_init, total_days = 200, samplesPerDay=np.inf, **kwargs):\n",
    "    # Run the simulation\n",
    "    \n",
    "    if kwargs[\"debugReturnNewPerDay\"]: # Keep the second copy as well\n",
    "        cur_stateTensor = np.reshape(\n",
    "            np.stack([copy.deepcopy(stateTensor_init), copy.deepcopy(stateTensor_init)], axis=0),-1)\n",
    "    else:\n",
    "        cur_stateTensor = np.reshape(copy.deepcopy(stateTensor_init),-1)\n",
    "    \n",
    "    if np.isinf(samplesPerDay):\n",
    "        # Run precise integrator - used for all simulations\n",
    "        out = integrate.solve_ivp(\n",
    "            fun = lambda t,y: dydt_Complete(t,y, **kwargs),\n",
    "            t_span=(0.,total_days),\n",
    "            y0 = cur_stateTensor,\n",
    "            method='RK23',\n",
    "            t_eval=range(total_days),\n",
    "            rtol = 1e-3, #default 1e-3\n",
    "            atol = 1e-3, # default 1e-6\n",
    "        )\n",
    "        \n",
    "        out = out.y\n",
    "        \n",
    "    else:\n",
    "        # Run simple Euler method with given step size (1/samplesPerDay) for quickly investigating code behavior\n",
    "        deltaT = 1./samplesPerDay\n",
    "        out = np.zeros((np.prod(stateTensor_init.shape),total_days))\n",
    "                       \n",
    "        for tt in range(total_days*samplesPerDay):\n",
    "            if tt % samplesPerDay==0:\n",
    "                out[:, int(tt/samplesPerDay)] = cur_stateTensor\n",
    "                       \n",
    "            cur_stateTensor += deltaT * dydt_Complete((tt*1.)/(1.*samplesPerDay),cur_stateTensor, **kwargs)\n",
    "            \n",
    "    \n",
    "    # Reshape to reasonable format\n",
    "    if kwargs[\"debugReturnNewPerDay\"]:\n",
    "        out = np.reshape(out, (2,) + stateTensor_init.shape+(-1,))\n",
    "    else:\n",
    "        out = np.reshape(out, stateTensor_init.shape+(-1,))\n",
    "    \n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment below for an example short run of the full model with base parameters and quarantining policy turned on.\n",
    "# # Takes ~2 mins on single CPU core.\n",
    "\n",
    "# # Build a dictionary out of arguments with defaults\n",
    "# paramDict_default = build_paramDict(dydt_Complete)\n",
    "# paramDict_default[\"dydt_Complete\"] = dydt_Complete\n",
    "# paramDict_default[\"INIT_stateTensor_init\"] = stateTensor_init\n",
    "\n",
    "# # Example way to set parameters conveniently, here we start quarantining early based on test results\n",
    "# paramDict_current = copy.deepcopy(paramDict_default)\n",
    "# paramDict_current[\"tStartQuarantineCaseIsolation\"] = pd.to_datetime(\"2020-03-23\", format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# out1 = solveSystem(\n",
    "#     stateTensor_init,\n",
    "#     total_days = 80,\n",
    "#     **paramDict_current\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a flat model function to use with outside callers\n",
    "\n",
    "Having the model defined flexible above, here we make it convenient to use to access any parameters, and to use with arbitrary outside optimisers / distributed workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary out of arguments with defaults\n",
    "paramDict_default = build_paramDict(dydt_Complete)\n",
    "paramDict_default[\"dydt_Complete\"] = dydt_Complete\n",
    "paramDict_default[\"INIT_stateTensor_init\"] = stateTensor_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramTable_default = paramDict_toTable(paramDict_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sets of params to differentiate between\n",
    "paramTypes = OrderedDict()\n",
    "\n",
    "paramTypes[\"basic\"] = [\n",
    "    # Definitions\n",
    "    'debugTransition', 'debugTimestep', 'debugReturnNewPerDay', \n",
    "    'nAge', 'nHS', 'nI', 'nR', 'nIso', 'nTest',\n",
    "    # Real data input\n",
    "    'trFunc_testing_params_inpFunc_realData_testCapacity',\n",
    "    'trFunc_testing_params_inpFunc_realData_testCapacity_params_realTestData',\n",
    "    'tStartSocialDistancing',\n",
    "    # State initialisation (no assumptions about COVID!)\n",
    "    'INIT_stateTensor_init'\n",
    "]\n",
    "\n",
    "paramTypes[\"functions\"] = [\n",
    "    'trFunc_diseaseProgression', \n",
    "    'trFunc_newInfections',\n",
    "    'trFunc_travelInfectionRate_ageAdjusted',\n",
    "    'trFunc_HospitalAdmission',\n",
    "    'trFunc_HospitalDischarge',\n",
    "    'trFunc_testing',\n",
    "    'trFunc_testing_params_policyFunc',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_f_symptoms_nonCOVID',\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications',\n",
    "    'trFunc_testing_params_trFunc_testCapacity',\n",
    "    'trFunc_quarantine',\n",
    "    'dydt_Complete'\n",
    "]\n",
    "\n",
    "\n",
    "paramTypes[\"ensemble\"] = [\n",
    "    'realStartDate',\n",
    "    \n",
    "    # Travel infections\n",
    "    'trFunc_travelInfectionRate_ageAdjusted_params_travelMaxTime',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelBaseRate',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelDecline_mean',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelDecline_slope',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelInfection_peak',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelInfection_maxloc',\n",
    "       'trFunc_travelInfectionRate_ageAdjusted_params_travelInfection_shape',\n",
    "    \n",
    "    # new infections\n",
    "    'trFunc_newInfections_params_ageSocialMixingBaseline',\n",
    "       'trFunc_newInfections_params_ageSocialMixingDistancing',\n",
    "       'trFunc_newInfections_params_withinHospitalSocialMixing',\n",
    "       'trFunc_newInfections_params_transmissionInfectionStage',\n",
    "    \n",
    "    # disease progression\n",
    "    'trFunc_diseaseProgression_params_nonsymptomatic_ratio',\n",
    "    'trFunc_diseaseProgression_params_infect_to_symptoms',\n",
    "    'trFunc_diseaseProgression_params_symptom_to_recovery',\n",
    "    'trFunc_diseaseProgression_params_symptom_to_hospitalisation',\n",
    "    'trFunc_diseaseProgression_params_hospitalisation_to_recovery',\n",
    "    'trFunc_diseaseProgression_params_IgG_formation',\n",
    "    'trFunc_diseaseProgression_params_caseFatalityRatioHospital_given_COVID_by_age',\n",
    "    'trFunc_diseaseProgression_params_ageRelativeRecoverySpeed',\n",
    "    'trFunc_diseaseProgression_params_nonsymp_to_recovery',\n",
    "    'trFunc_diseaseProgression_params_inverse_IS1_IS2',\n",
    "    \n",
    "    # Hospitalisation\n",
    "    'trFunc_HospitalAdmission_params_ageHospitalisationRateBaseline',\n",
    "   'trFunc_HospitalAdmission_params_infToHospitalExtra',\n",
    "   'trFunc_HospitalAdmission_params_ageRelativeExtraAdmissionRiskToCovid',\n",
    "   'trFunc_HospitalDischarge_params_ageHospitalisationRecoveryRateBaseline',\n",
    "   'trFunc_HospitalDischarge_params_dischargeDueToCovidRateMultiplier',\n",
    "    \n",
    "    # PCR testing? \n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_PCR_FNR_I1_to_R2',\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_PCR_FPR',\n",
    "    \n",
    "    # Symptoms\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_f_symptoms_nonCOVID_params_symptomsIliRCGP',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_f_symptoms_nonCOVID_params_symptomsRespInHospitalFAEs'\n",
    "]\n",
    "\n",
    "\n",
    "paramTypes[\"policy\"] = [    \n",
    "    # Timings\n",
    "    'tStopSocialDistancing',\n",
    "    'tStartImmunityPassports', 'tStopImmunityPassports',\n",
    "    'tStartQuarantineCaseIsolation', 'tStopQuarantineCaseIsolation',\n",
    "    \n",
    "    # Quarantine\n",
    "    'trFunc_quarantine_params_nDaysInHomeIsolation',\n",
    "    'trFunc_newInfections_params_ageSocialMixingIsolation',\n",
    "    'trFunc_quarantine_params_timeToIsolation',\n",
    "    'trFunc_quarantine_params_symptomHospitalisedRate_ageAdjusted',\n",
    "    'trFunc_quarantine_params_symptomaticHealthStates',\n",
    "    \n",
    "    # Testing\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_phe_total',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_phe_inflexday',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_phe_inflexslope',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_country_total',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_country_inflexday',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_pcr_country_inflexslope',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_antibody_country_firstday',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_antibody_country_total',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_antibody_country_inflexday',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_antibody_country_inflexslope',\n",
    "    'trFunc_testing_params_trFunc_testCapacity_params_testCapacity_antigenratio_country',\n",
    "    \n",
    "    'trFunc_testing_params_policyFunc_params_retesting_antigen_immunepos_ratio',\n",
    "    'trFunc_testing_params_policyFunc_params_retesting_antibody_immunepos_ratio',\n",
    "    \n",
    "    'trFunc_testing_params_policyFunc_params_return_testsAvailable_remaining',\n",
    "    \n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_antibody_testing_policy',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_distributeRemainingToRandom',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_distributeRemainingToRandom',\n",
    "    'trFunc_testing_params_policyFunc_params_basic_policyFunc_params_return_testsAvailable_remaining',\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Test specs\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_antigen_FNR_I1_to_R2',\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_antigen_FPR',\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_antibody_FNR_I1_to_R2',\n",
    "    'trFunc_testing_params_inpFunc_testSpecifications_params_antibody_FPR_S_to_I4'\n",
    "]\n",
    "\n",
    "# Check if we defined all params and nothing extra\n",
    "print(set(paramTable_default.columns) - set([b for a in paramTypes.values() for b in a]))\n",
    "print(set([b for a in paramTypes.values() for b in a]) - set(paramTable_default.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save paramTypes to use in other notebooks\n",
    "# with open('paramTypes.cpkl', 'wb') as fh:\n",
    "#     cloudpickle.dump(paramTypes, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"defineEnsemblePriors\"></a>\n",
    "# Define sensible priors and normalised distances in parameter space for Bayesian exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleParamPriors = OrderedDict()\n",
    "for paramName in paramTypes[\"ensemble\"]:\n",
    "    curParam = paramTable_default[paramName].loc[0]\n",
    "    ensembleParamPriors[paramName] = OrderedDict(\n",
    "        type = type(curParam),\n",
    "        size =  curParam.shape if isinstance(curParam, np.ndarray) else (1,),\n",
    "        defaultVal = curParam\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "# Define \"sampleFunc\" sampling functions for all non-standard things,\n",
    "# then all the rest just define as underdispersed gamma distributions with mean matching the default value\n",
    "\n",
    "# Also define \"distFunc\", which helps us define distance from other samples \n",
    "# (makes sure the individual dimensions are on similar distance scales for the GP regression, so we \"zscore\" each)\n",
    "\n",
    "# Helper func for zscoreing scaled beta dist\n",
    "def getBetaStd(m,a,b):\n",
    "    return m * np.sqrt( (a*b)/((a+b)**2 * (a+b+1)))\n",
    "\n",
    "\n",
    "\n",
    "# Staring day of simulation\n",
    "# -------------------------\n",
    "\n",
    "# Just pick uniformly randomly from a range\n",
    "ensembleParamPriors[\"realStartDate\"][\"sampleFunc\"] = (\n",
    "    lambda : random.sample(list(pd.date_range('2020-01-30','2020-03-05', freq='D')),1)[0]\n",
    ")\n",
    "ensembleParamPriors[\"realStartDate\"][\"distFunc\"] = (\n",
    "    lambda x,y: np.abs((x-y).days)/(np.sqrt(1./12.*36**2))\n",
    ")\n",
    "\n",
    "\n",
    "# SOCIAL MIXING\n",
    "# -------------\n",
    "\n",
    "# For baseline social mixing we can just take the given values, should be reasonably well established\n",
    "ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingBaseline'][\"sampleFunc\"] = (\n",
    "    lambda d=ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingBaseline'][\"defaultVal\"]: d\n",
    ")\n",
    "ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingBaseline'][\"distFunc\"] = lambda x,y: 0.\n",
    "\n",
    "# For social distancing things are a little less clear. \n",
    "# We'll assume that the general mixing ratio changes amongst age groups caused by social distancing are correct,\n",
    "# And we just multiply the overall level of social interactions\n",
    "\n",
    "ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingDistancing'][\"sampleFunc\"] = (\n",
    "    lambda d = ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingDistancing'][\"defaultVal\"]: (\n",
    "        d\n",
    "        *\n",
    "        (np.random.beta(2,3) * 2) # Mostly smaller than 1 values, but can be larger, mean is 0.8 like this\n",
    "    )\n",
    ")\n",
    "ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingDistancing'][\"distFunc\"] = (\n",
    "    # Distances are all caused by the beta prior, so let's just figure out the distance in \"beta distribution space\",\n",
    "    # and normalise the variance to 1\n",
    "    lambda x,y,d=ensembleParamPriors['trFunc_newInfections_params_ageSocialMixingDistancing'][\"defaultVal\"]: (\n",
    "        # Get abs(first beta sample - second beta sample) and divide by expected std sqrt((ab/((a+b)^2*(a+b+1)))**2) = 0.4 \n",
    "        np.abs(\n",
    "            np.mean(x/d)\n",
    "            -\n",
    "            np.mean(y/d)\n",
    "        ) \n",
    "        / getBetaStd(2,2,3)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Infectiusness\n",
    "# --------------\n",
    "\n",
    "# This the one we're most uncertain about, define a broad prior. \n",
    "# We do expect E and IN to be not very infectious (non-symptomatic cases)\n",
    "# Whereas we do expect IS1 and IS2 to be much more infectious (symptomatic cases)\n",
    "\n",
    "ensembleParamPriors['trFunc_newInfections_params_transmissionInfectionStage'][\"sampleFunc\"] = (\n",
    "    lambda : (\n",
    "        np.stack([\n",
    "            # Very low E state infectiousness with max rate 0.2\n",
    "            0.2 * np.random.beta(1,5),\n",
    "            # Low IN state infectiousness with max rate 0.5\n",
    "            0.5 * np.random.beta(1,3),\n",
    "            # High IS1 state infectiousness with max rate 2. (average 0.8)\n",
    "            2* np.random.beta(2,3),\n",
    "            \n",
    "            # High IS2 state infectiousness with max rate 1.6\n",
    "            1.6* np.random.beta(2,3)\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "# zscore all dims independently then average the 4 distances\n",
    "ensembleParamPriors['trFunc_newInfections_params_transmissionInfectionStage'][\"distFunc\"] = (\n",
    "    # Distances are all caused by the beta prior, so let's just figure out the distance in \"beta distribution space\",\n",
    "    # and normalise the variance to 1\n",
    "    lambda x,y: np.mean(\n",
    "        # Get abs(first beta sample - second beta sample) and divide by expected std sqrt((ab/((a+b)^2*(a+b+1)))**2) = 0.4 \n",
    "        np.abs(x - y) \n",
    "        / np.stack([getBetaStd(0.2,1,5), getBetaStd(0.5,2,3), getBetaStd(2,2,3), getBetaStd(1.6,2,3)])\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Disease progression\n",
    "# -------------------\n",
    "\n",
    "# This one's based on the CHESS dataset exactly, so we only allow for little (but independent) variation around the computed values\n",
    "ensembleParamPriors['trFunc_diseaseProgression_params_caseFatalityRatioHospital_given_COVID_by_age'][\"sampleFunc\"] = (\n",
    "    lambda d=ensembleParamPriors['trFunc_diseaseProgression_params_caseFatalityRatioHospital_given_COVID_by_age'][\"defaultVal\"] : (\n",
    "        d    \n",
    "        *\n",
    "        np.stack([ # make for each parameter independent beta numbers in range 0.75-1.25 to multiply\n",
    "            0.5*np.random.beta(5,5)+0.75\n",
    "            for _ in range(len(d))\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "ensembleParamPriors['trFunc_diseaseProgression_params_caseFatalityRatioHospital_given_COVID_by_age'][\"distFunc\"] = (\n",
    "    lambda x,y,d=ensembleParamPriors['trFunc_diseaseProgression_params_caseFatalityRatioHospital_given_COVID_by_age'][\"defaultVal\"]: np.mean(\n",
    "        np.abs(\n",
    "            x/d\n",
    "            -\n",
    "            y/d\n",
    "        )\n",
    "        / getBetaStd(0.5, 5, 5)\n",
    "    ) # LET's do importance weigthing outside! * 0.25 # Because this is a strong assumption based on data, and with little variation in samples, I want the distances in sample space to matter less!\n",
    ")\n",
    "\n",
    "\n",
    "# This one is simply an assumption that younger people recover more / faster, let's just sample it as randn\n",
    "ensembleParamPriors['trFunc_diseaseProgression_params_ageRelativeRecoverySpeed'][\"sampleFunc\"] = (\n",
    "    lambda d = ensembleParamPriors['trFunc_diseaseProgression_params_ageRelativeRecoverySpeed'][\"defaultVal\"]: np.clip(\n",
    "        0.5 * np.sort(\n",
    "                np.random.randn(*d.shape)\n",
    "            )[::-1],\n",
    "        -0.99, np.inf\n",
    "    )\n",
    ")\n",
    "ensembleParamPriors['trFunc_diseaseProgression_params_ageRelativeRecoverySpeed'][\"distFunc\"] = (\n",
    "    # we need to \"undo\" the sorting operation that resulted in x and y, thus take all pairwise distances, which \n",
    "    # should simply come from normal distribution\n",
    "    lambda x,y: 0. if (x == y).all() else (np.mean( \n",
    "        np.abs(x[:,np.newaxis] - y[np.newaxis,:])\n",
    "    ) / 0.5) # to zscore\n",
    ")\n",
    "\n",
    "\n",
    "# HOSPITALISATION\n",
    "# ----------------\n",
    "\n",
    "\n",
    "# These next two comes fully from NHS HES data, don't change it for now!\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_ageHospitalisationRateBaseline'][\"sampleFunc\"] = (\n",
    "    lambda d=ensembleParamPriors['trFunc_HospitalAdmission_params_ageHospitalisationRateBaseline'][\"defaultVal\"]: d\n",
    ")\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_ageHospitalisationRateBaseline'][\"distFunc\"] = (\n",
    "    lambda x,y: 0.\n",
    ")\n",
    "ensembleParamPriors['trFunc_HospitalDischarge_params_ageHospitalisationRecoveryRateBaseline'][\"sampleFunc\"] =(\n",
    "    lambda d=ensembleParamPriors['trFunc_HospitalDischarge_params_ageHospitalisationRecoveryRateBaseline'][\"defaultVal\"]: d\n",
    ")\n",
    "ensembleParamPriors['trFunc_HospitalDischarge_params_ageHospitalisationRecoveryRateBaseline'][\"distFunc\"] =(\n",
    "    lambda x,y: 0.\n",
    ")\n",
    "\n",
    "\n",
    "# These ones are very important, and largely unknown, so let's define broad priors and explore them!\n",
    "\n",
    "# This is extra rate of being hospitalised because of being in infection states E,IN, IS1, IS2, BEFORE AGE ADJUSTMENT\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_infToHospitalExtra'][\"sampleFunc\"] = (\n",
    "    lambda : (\n",
    "        np.stack([\n",
    "            # Very low E state with max rate 0.01 (1% chance)\n",
    "            0.01 * np.random.beta(1,7),\n",
    "            # Very low IN state with max rate 0.02 \n",
    "            0.02 * np.random.beta(1,6),\n",
    "            # Slighty higher very broad IS1 state infectiousness with max rate 0.1 (average 5%)\n",
    "            0.1* np.random.beta(1.5,1.5),\n",
    "            \n",
    "            # Slighty higher very broad IS2 state infectiousness with max rate 0.1 (average 5%)\n",
    "            0.1* np.random.beta(1.5,1.5),\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_infToHospitalExtra'][\"distFunc\"] = (\n",
    "    # Distances are all caused by the beta prior, so let's just figure out the distance in \"beta distribution space\",\n",
    "    # and normalise the variance to 1\n",
    "    lambda x,y: np.mean(\n",
    "        # Get abs(first beta sample - second beta sample) and divide by expected std sqrt((ab/((a+b)^2*(a+b+1)))**2) = 0.4 \n",
    "        np.abs(x - y) \n",
    "        / np.stack([getBetaStd(0.01,1,7), getBetaStd(0.02,1,6), getBetaStd(0.1,1.5,1.5), getBetaStd(0.1,1.5,1.5)])\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# This one adjusts the above extra risks to differ amongst different age groups. \n",
    "# The actual observed admissions are based on data, but we still want to vary them slightly and independetly\n",
    "# Instead of multiplication, here we'll add normally distributed rates\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_ageRelativeExtraAdmissionRiskToCovid'][\"sampleFunc\"] = (\n",
    "    lambda d = ensembleParamPriors['trFunc_HospitalAdmission_params_ageRelativeExtraAdmissionRiskToCovid'][\"defaultVal\"]: (\n",
    "        np.clip( d +  0.2 * np.random.randn(*d.shape), -0.99, np.inf)            \n",
    "    )\n",
    ")\n",
    "\n",
    "ensembleParamPriors['trFunc_HospitalAdmission_params_ageRelativeExtraAdmissionRiskToCovid'][\"distFunc\"] = (\n",
    "    # Simple average distance of already-zscored (to 0.5 std) variables x-y\n",
    "    lambda x,y: np.mean( \n",
    "        np.abs(x - y)\n",
    "    ) / 0.5 # to zscore\n",
    ")\n",
    "\n",
    "\n",
    "# TESTING\n",
    "# -------\n",
    "\n",
    "# Set some broad priors on overall PCR efficiency\n",
    "ensembleParamPriors['trFunc_testing_params_inpFunc_testSpecifications_params_PCR_FNR_I1_to_R2'][\"sampleFunc\"] = (\n",
    "    lambda : (\n",
    "        np.stack([\n",
    "            # E between 0.4-1.\n",
    "            0.6 * np.random.beta(1.5,1.5) + 0.4,\n",
    "            # IN between 0.2-0.6\n",
    "            0.4 * np.random.beta(1.5,1.5) + 0.2,\n",
    "            # IS1 between 0.01-0.35\n",
    "            0.34 * np.random.beta(1.5,1.5) + 0.01,\n",
    "            # IS2 between 0.05-0.55\n",
    "            0.5 * np.random.beta(1.5,1.5) + 0.05,\n",
    "            # R1 between 0.3-0.7\n",
    "            0.4 * np.random.beta(1.5,1.5) + 0.3,\n",
    "            # R1 between 0.4-1.\n",
    "            0.6 * np.random.beta(1.5,1.5) + 0.4\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "ensembleParamPriors['trFunc_testing_params_inpFunc_testSpecifications_params_PCR_FNR_I1_to_R2'][\"distFunc\"] = (\n",
    "    # Distances are all caused by the beta prior, so let's just figure out the distance in \"beta distribution space\",\n",
    "    # and normalise the variance to 1\n",
    "    lambda x,y: np.mean(\n",
    "        # Get abs(first beta sample - second beta sample) and divide by expected std sqrt((ab/((a+b)^2*(a+b+1)))**2) = 0.4 \n",
    "        np.abs(x - y) \n",
    "        / np.stack(\n",
    "            [getBetaStd(0.6,1.5,1.5), getBetaStd(0.4,1.5,1.5), getBetaStd(0.34,1.5,1.5), getBetaStd(0.5,1.5,1.5), getBetaStd(0.4,1.5,1.5), getBetaStd(0.6,1.5,1.5)])\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ALL OTHER SINGLE SCALAR NUMERIC PARAMETER VALUES (largely \"days\")\n",
    "# --------------------------------------------------------\n",
    "# We just define them as multiplied by beta distributed numbers between 0.5-1.5 to adjust the rates\n",
    "for key in ensembleParamPriors.keys():\n",
    "    if \"sampleFunc\" not in ensembleParamPriors[key]:\n",
    "            ensembleParamPriors[key][\"sampleFunc\"] = (\n",
    "                lambda d=copy.deepcopy(ensembleParamPriors[key][\"defaultVal\"]), t=copy.deepcopy(ensembleParamPriors[key][\"type\"]): np.cast[t](\n",
    "                    (1. * np.random.beta(3.,3.) + 0.5)\n",
    "                    *\n",
    "                    d\n",
    "                )\n",
    "            )\n",
    "            ensembleParamPriors[key][\"distFunc\"] = (\n",
    "                lambda x,y,d=copy.deepcopy(ensembleParamPriors[key][\"defaultVal\"]): (\n",
    "                        # Get abs(first beta sample - second beta sample) and divide by expected std sqrt((ab/((a+b)^2*(a+b+1)))**2) = 0.4 \n",
    "                        np.abs(\n",
    "                            (x / d)\n",
    "                            - \n",
    "                            (y / d)\n",
    "                        ) \n",
    "                        / getBetaStd(1.,3.,3.)\n",
    "                    )\n",
    "            )\n",
    "\n",
    "        \n",
    "# Naive pairwise dist implementation for arbitary objects of the same type\n",
    "def getPairwiseDistsSingleDim(distFunc, listOfObjects, listOfObjectsOther=None):#, symmetricDist=True): # we assume symmetric distance\n",
    "    if listOfObjectsOther is None:\n",
    "        listOfObjectsOther = listOfObjects \n",
    "        squareOutput = True\n",
    "    else:\n",
    "        squareOutput = False\n",
    "    \n",
    "    out = np.zeros((len(listOfObjects), len(listOfObjectsOther)))\n",
    "    \n",
    "    for i in range(len(listOfObjects)):\n",
    "        j_start = i+1 if squareOutput else 0\n",
    "        for j in range(j_start, len(listOfObjectsOther)):\n",
    "            out[i,j] = distFunc(listOfObjects[i], listOfObjectsOther[j])\n",
    "            \n",
    "    if squareOutput:\n",
    "        out = out + out.T\n",
    "                    \n",
    "    return out\n",
    "    \n",
    "    \n",
    "# # Make sure that all simulation average distances (except the deterministic samplers) are on the same scale: \n",
    "# print(\"Average distances between samples for 100 samples, should be ~1.1 or 0. for static things\")\n",
    "# print(\"-----------------------------------------------------------------------------------------\")\n",
    "# for key in ensembleParamPriors:\n",
    "#     tmp = getPairwiseDistsSingleDim(\n",
    "#         ensembleParamPriors[key][\"distFunc\"],\n",
    "#         [ensembleParamPriors[key][\"sampleFunc\"]() for i in range(100)]\n",
    "#     )\n",
    "\n",
    "#     print(\n",
    "#         np.mean(tmp[np.triu_indices_from(tmp, k=1)]), key # this should be around 1.1 for every variable, the average distance of z-scored floats\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEnsembleParamSample(num_samples = 1, ensembleParamPriors=ensembleParamPriors):\n",
    "    \"\"\"\n",
    "    Ensemble parameters do not have to live on a grid, just try and sample them from given priors\n",
    "    \"\"\"\n",
    "    if num_samples == 1:\n",
    "        newParamDict = OrderedDict()\n",
    "        for key in ensembleParamPriors:\n",
    "            newParamDict[key] = ensembleParamPriors[key][\"sampleFunc\"]()\n",
    "\n",
    "        #return newParamDict\n",
    "        return pd.DataFrame([newParamDict.values()], columns=newParamDict.keys())\n",
    "    else:\n",
    "        for i in range(num_samples):\n",
    "            if i==0:\n",
    "                df_out = getEnsembleParamSample(num_samples = 1, ensembleParamPriors=ensembleParamPriors)\n",
    "            else:\n",
    "                df_out = df_out.append(getEnsembleParamSample(num_samples = 1, ensembleParamPriors=ensembleParamPriors))\n",
    "        \n",
    "        df_out = df_out.reset_index(drop=True)\n",
    "        return df_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEnsembleParamSampleDistance(df1, df2=None, weighting = None, ensembleParamPriors=ensembleParamPriors):\n",
    "    \"\"\"\n",
    "    Given two sets of ensemble parameter samples in pandas dataframes (as output by getEnsembleParamSample), \n",
    "    # returns the pairwise distance between all\n",
    "    This relies on having individual distance metrics in each parameter type `axis`\n",
    "    \"\"\"\n",
    "    if df2 is not None:\n",
    "        out = np.zeros((len(df1), len(df2)))\n",
    "    else:\n",
    "        df2 = df1\n",
    "        out = np.zeros((len(df1), len(df2)))\n",
    "\n",
    "    # If no pre-defined weighting of columns' distances (default is 1), then use equal weigthing\n",
    "    weighting = OrderedDict() if weighting is None else weighting\n",
    "        \n",
    "    # Go through each key, \n",
    "    # get the within-axis pairwise distances\n",
    "    # add their squares to the out matrix (we'll take the sqrt of the mean afterwards to get overall eucl distance)\n",
    "    for key in ensembleParamPriors:\n",
    "        cur_weight = weighting[key] if key in weighting else 1.\n",
    "        out += (\n",
    "            cur_weight*\n",
    "            getPairwiseDistsSingleDim(\n",
    "                distFunc = ensembleParamPriors[key][\"distFunc\"],\n",
    "                listOfObjects = list(df1[key]),\n",
    "                listOfObjectsOther = list(df2[key])\n",
    "            )\n",
    "        )**2\n",
    "        \n",
    "      \n",
    "\n",
    "    out = np.sqrt(out)\n",
    "        \n",
    "    return out\n",
    "            \n",
    "                \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all target likelihoods we define initial mean and variance (largely based on earlier random run results, see histogtam in plotEnsembles!)\n",
    "def getGPR_prediction(\n",
    "    df_sor, \n",
    "    df_new, \n",
    "    dist_func = getEnsembleParamSampleDistance,\n",
    "    target_likelihoods = OrderedDict( # descibes the column name in df_sor, and the mean function and output variance of the kernel for that likelihood\n",
    "        likelihood_0 = OrderedDict(mean=0., var=400.**2),\n",
    "        likelihood_1 = OrderedDict(mean=0., var=600.**2),\n",
    "        likelihood_2 = OrderedDict(mean=0., var=500.**2),\n",
    "        likelihood_3 = OrderedDict(mean=0., var=1500.**2),\n",
    "        likelihood_total = OrderedDict(mean=0., var=5000.**2)\n",
    "#         likelihood_0 = OrderedDict(mean=-200., var=100.**2),\n",
    "#         likelihood_1 = OrderedDict(mean=-500., var=200.**2),\n",
    "#         likelihood_2 = OrderedDict(mean=-300., var=100.**2),\n",
    "#         likelihood_3 = OrderedDict(mean=-1700., var=500.**2),\n",
    "#         likelihood_total = OrderedDict(mean=-3000., var=1000.**2)\n",
    "    ), \n",
    "    kernel_dist_scale2 = 10., # (average dist^2 is 48, so this sets its to exp-2=0.13 on average)\n",
    "    Ksor_inv=None, # pass the precomputed inverse kernel matrix on df_sor if it hasn't changed\n",
    "    return_Ksor_only = False\n",
    "    ):\n",
    "    \n",
    "    # Compute the inverse kernel matrix if doesn't exist yet\n",
    "    if Ksor_inv is None:\n",
    "        return_Ksor_inv = True\n",
    "        Ksor_inv = np.exp(-dist_func(df_sor)**2/(2.*kernel_dist_scale2))\n",
    "        Ksor_inv = np.linalg.inv(Ksor_inv + 1e-12*np.eye(*Ksor_inv.shape))\n",
    "        if return_Ksor_only:\n",
    "            return Ksor_inv\n",
    "    else:\n",
    "        return_Ksor_inv = False\n",
    "        \n",
    "    # Set the new only kernel (independent points)\n",
    "    Knew = np.eye(len(df_new))\n",
    "    \n",
    "    # Comute the cross-kernel\n",
    "    Kcross = np.exp(-dist_func(df_new, df_sor)**2/(2.*kernel_dist_scale2))\n",
    "    \n",
    "    # for each target likelihood, add the predicted likelihoods as columns to df_new\n",
    "    \n",
    "    for lik_col in target_likelihoods.keys():\n",
    "        # Fill in the predicted mean\n",
    "        df_new[\"GPR_pred_mean_\"+lik_col] = (\n",
    "            target_likelihoods[lik_col][\"mean\"] + # mean function\n",
    "            (\n",
    "                np.matmul(\n",
    "                    Kcross,\n",
    "                    np.matmul(\n",
    "                        Ksor_inv,\n",
    "                        df_sor[lik_col].values - target_likelihoods[lik_col][\"mean\"] # observed - mean function\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Fill in the predicted standard deviation (reduced compared to the baseline given in target_likelihoods[var])\n",
    "        df_new[\"GPR_pred_std_\"+lik_col] = np.sqrt(\n",
    "            target_likelihoods[lik_col][\"var\"] * # output variance\n",
    "            np.diag(\n",
    "                Knew\n",
    "                -\n",
    "                np.matmul(\n",
    "                    Kcross,\n",
    "                    np.matmul(\n",
    "                        Ksor_inv,\n",
    "                        Kcross.T\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if return_Ksor_inv:\n",
    "        return df_new, Ksor_inv\n",
    "    else:\n",
    "        return df_new\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment below to run example sampling + GP regression\n",
    "\n",
    "# # Sample a few param sets as an example\n",
    "# tmp = getEnsembleParamSample(10)\n",
    "\n",
    "# # Test the GP regression from above\n",
    "# for i in range(4):\n",
    "#     tmp[\"likelihood_\"+str(i)] = -500+100*np.random.randn(10,)\n",
    "    \n",
    "# tmp[\"likelihood_total\"] = tmp.loc[:,list(tmp.columns.str.startswith(\"likelihood_\"))].sum(1)\n",
    "    \n",
    "# for i in range(3):\n",
    "#     if i == 0:\n",
    "#         tmp_new =  getEnsembleParamSample()\n",
    "#     else:\n",
    "#         tmp_new = tmp_new.append(getEnsembleParamSample())\n",
    "        \n",
    "# tmp_new = tmp_new.reset_index(drop=True)\n",
    "\n",
    "# out1, Ksor_inv = getGPR_prediction(\n",
    "#     tmp, tmp_new\n",
    "# )\n",
    "\n",
    "# out2 = getGPR_prediction(\n",
    "#     tmp, tmp_new, Ksor_inv= Ksor_inv \n",
    "# )\n",
    "\n",
    "# out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate simulation likelihood given data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHS England deaths dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHS daily deaths report (about 24 hours behind)\n",
    "# TODO - might need to manually update link and column numbers (maybe not consistent across days, cannot yet automate)\n",
    "# NOTE - NHS started deleting their old files, and now only the latest seems to be available...\n",
    "df_UK_NHS_daily_COVID_deaths = pd.read_excel(\n",
    "    \"https://www.england.nhs.uk/statistics/wp-content/uploads/sites/2/2020/04/COVID-19-total-announced-deaths-20-April-2020.xlsx\",\n",
    "    sheet_name = \"COVID19 total deaths by age\",\n",
    "    index_col=0,\n",
    "    usecols = \"B,E:AX\",\n",
    "    skip_rows = range(17),\n",
    "    nrows = 22\n",
    ").iloc[14:].transpose().set_index(\"Age group\").rename_axis(index = \"Date\", columns = \"AgeGroup\")\n",
    "\n",
    "df_UK_NHS_daily_COVID_deaths.index = pd.to_datetime(df_UK_NHS_daily_COVID_deaths.index, format=\"%Y-%m-%d\")\n",
    "\n",
    "df_UK_NHS_daily_COVID_deaths = df_UK_NHS_daily_COVID_deaths.drop(df_UK_NHS_daily_COVID_deaths.columns[:2], axis=1)\n",
    "\n",
    "df_UK_NHS_daily_COVID_deaths\n",
    "\n",
    "# Ignore very recent unreliable data points\n",
    "df_UK_NHS_daily_COVID_deaths = df_UK_NHS_daily_COVID_deaths.loc[\n",
    "            df_UK_NHS_daily_COVID_deaths.index <= CONST_DATA_CUTOFF_DATE]\n",
    "\n",
    "df_UK_NHS_daily_COVID_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHS England CHESS - COVID hospitalisations - dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the aggregate data (ask @SebastianVollmer for aggregation details and or data access!)\n",
    "df_CHESS = pd.read_csv(\"/mnt/efs/data/CHESS_Aggregate20200417.csv\").drop(0)\n",
    "\n",
    "# Clean the dates and make them index\n",
    "# The \"1899-12-30\" is simply total, ignore that.\n",
    "# The 2020-09-03, 2020-10-03, 2020-11-03, 2020-12-03 are parsed wrong and are march 09-12 supposedly.\n",
    "# The data collection is only officially started across england on 09 March, the February dates seem empty, delete.\n",
    "# Rest are ok\n",
    "\n",
    "df_CHESS.index = pd.to_datetime(df_CHESS[\"DateOfAdmission\"].values,format=\"%d-%m-%Y\")\n",
    "\n",
    "# Ignore too old and too recent data points\n",
    "df_CHESS = df_CHESS.sort_index().drop(\"DateOfAdmission\", axis=1).query('20200309 <= index <= ' + CONST_DATA_CUTOFF_DATE)\n",
    "\n",
    "df_CHESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHESS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hospitalised people who tested positive for COVID, using cumsum (TODO: for now assuming they're all still in hospital)\n",
    "df_CHESS_newCOVID = df_CHESS.loc[:,df_CHESS.columns.str.startswith(\"AllAdmittedPatientsWithNewLabConfirmedCOVID19\")]\n",
    "\n",
    "df_CHESS_newCOVID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example simulation:\n",
    "simExample = np.load(\"/mnt/efs/results/run_20200408T195337/outTensor_20200408T195337_slr7ep10hy0q9iyr3k36.npy\")\n",
    "simExample_newOnly = np.load(\"/mnt/efs/results/run_20200408T195337/outTensor_20200408T195337_slr7ep10hy0q9iyr3k36_newOnly.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We expect \n",
    "def joinDataAndSimCurves(\n",
    "    df_curves, # a pandas dataframe with dates as index, and each column is a curve\n",
    "    simCurves, # curves x time np array\n",
    "    simStartDate, # curves start dates\n",
    "    simCurvesNames = None,\n",
    "    fulljoin = False # if true, then one keeps all dates in the simulation, instead of just the ones in the date \n",
    "    ):\n",
    "    \n",
    "    out_df = copy.deepcopy(df_curves)\n",
    "    \n",
    "    simCurveIndex = pd.date_range(start=simStartDate, freq='D', periods=simCurves.shape[1])\n",
    "    \n",
    "    if simCurvesNames is None:\n",
    "        simCurvesNames = [\"simCurve_{}\".format(i) for i in range(simCurves.shape[0])]\n",
    "    \n",
    "    join_type = \"outer\" if fulljoin else \"left\"\n",
    "    \n",
    "    for i, curve in enumerate(simCurves):\n",
    "        out_df = out_df.join(\n",
    "            pd.DataFrame(\n",
    "                index = simCurveIndex,\n",
    "                data = simCurves[i],\n",
    "                columns=[simCurvesNames[i]]\n",
    "            ),\n",
    "            how = join_type\n",
    "        )\n",
    "    \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegBinomParams(mu, alpha):\n",
    "    \"\"\" \n",
    "    From https://stats.stackexchange.com/questions/260580/negative-binomial-distribution-with-python-scipy-stats\n",
    "    Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float \n",
    "       Mean of NB distribution.\n",
    "    alpha : float\n",
    "       Overdispersion parameter used for variance calculation.\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations\n",
    "    \"\"\"\n",
    "    var = mu + alpha * mu ** 2\n",
    "    p = (var - mu) / var\n",
    "    r = mu ** 2 / (var - mu)\n",
    "    return r, p\n",
    "\n",
    "def NegBinom_logpmf(a, m, x):\n",
    "    binom_vec = np.array([binom(x1 + a - 1, x1) for x1 in x])\n",
    "    logpmf = np.log(binom_vec) + a * np.log(a / (m + a))  + x * np.log((m / (m + a)))\n",
    "    return logpmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deaths in hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likFunc_deaths(\n",
    "    sim, # use newOnly for deaths by day needed here\n",
    "    simStartDate, \n",
    "    df,\n",
    "    sumAges = True,\n",
    "    outputDataframe = False, # If true, outputs the data-curves and simulated curves instead of likelihood, for plotting\n",
    "    fulljoin = False # if true, then one keeps all dates in the simulation, instead of just the ones in the date\n",
    "    ):\n",
    "\n",
    "        \n",
    "    # Get deaths by day in simulation in hospitals for people with positive tests\n",
    "    deaths_Sim_byAge = np.sum(sim[:,-1,2,:,:],axis=(1))\n",
    "    \n",
    "    \n",
    "    if sumAges:\n",
    "        deaths_Sim = np.sum(deaths_Sim_byAge,axis=0, keepdims=True) \n",
    "        deaths_data = pd.DataFrame(df.sum(1))\n",
    "    else:\n",
    "        # Change the grouping of ages to be same as dataset\n",
    "        deaths_Sim_byAge_regroup = regroup_by_age(\n",
    "            deaths_Sim_byAge, \n",
    "            fromAgeSplits = np.arange(10,80+1,10), \n",
    "            toAgeSplits = np.arange(20,80+1,20)\n",
    "        )\n",
    "        \n",
    "        deaths_Sim = deaths_Sim_byAge_regroup\n",
    "        deaths_data = df\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Join the two dataframes to align in time\n",
    "    df_full = joinDataAndSimCurves(\n",
    "        df_curves = deaths_data, # a pandas dataframe with dates as index, and each column is a curve\n",
    "        simCurves = deaths_Sim, # curves x time np array\n",
    "        simStartDate = simStartDate, # curves start dates\n",
    "        fulljoin = fulljoin\n",
    "    )\n",
    "    \n",
    "    # If true, outputs the data-curves and simulated curves instead of likelihood, for plotting\n",
    "    if outputDataframe:\n",
    "        return df_full\n",
    "    \n",
    "    # We assume the order of columns in data and in simCurves are the same!\n",
    "    #return df_full\n",
    "    return np.nansum(\n",
    "        NegBinom_logpmf(2., \n",
    "                        # Select all simCurve columns and reshape to a single vector\n",
    "                        m = 1e-8+np.reshape(df_full.loc[:,df_full.columns.str.startswith(\"simCurve_\")==True].values,-1), \n",
    "                        # Select all data columns and reshape to a single vector\n",
    "                        x = np.reshape(df_full.loc[:,(df_full.columns.str.startswith(\"simCurve_\")==True)==False].values,-1)\n",
    "                       )\n",
    "    )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likFunc_deaths(\n",
    "    sim = simExample_newOnly, \n",
    "    simStartDate = '2020-02-12',\n",
    "    df = copy.deepcopy(df_UK_NHS_daily_COVID_deaths),\n",
    "    sumAges=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test outcomes in hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likFunc_newHospPositive(\n",
    "    sim, # Here we'll make sure to pass the \"_newOnly\" tensor!\n",
    "    simStartDate, \n",
    "    df,\n",
    "    sumAges = True,\n",
    "    outputDataframe = False, # If true, outputs the data-curves and simulated curves instead of likelihood, for plotting\n",
    "    fulljoin = False # if true, then one keeps all dates in the simulation, instead of just the ones in the date\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Get the number of hospitalised people testing positive each day.\n",
    "    This fits well with \"policyFunc_testing_symptomaticOnly\" being active, which prioratises testing hospitalised people\n",
    "    As per 09 April this is a very reasonable assumption\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the simulation curves of hospitalised people getting positive tests each day\n",
    "    # TODO - run the simulation with actual test numbers each day, would make fits a LOT better.\n",
    "    # Take into account the number of positive tested people who leave the hospital and add that as well \n",
    "    # (as they were also replaced by new people testing positive in the hospital!)\n",
    "    \n",
    "    # Change in hospital and testing positive\n",
    "    newHospPositives_sim = np.sum(sim[:,:,2,1,:], axis=(1,))\n",
    "    \n",
    "    if sumAges:\n",
    "        hospPos_Sim = np.sum(newHospPositives_sim,axis=0, keepdims=True) \n",
    "        hospPos_data = pd.DataFrame(df.sum(1))\n",
    "    else:\n",
    "        \n",
    "        # Change the grouping of ages to be same as dataset\n",
    "        \n",
    "        hospPos_Sim = regroup_by_age(\n",
    "            newHospPositives_sim, \n",
    "            fromAgeSplits = np.arange(10,80+1,10), \n",
    "            toAgeSplits = np.concatenate([np.array([1,5,15,25]),np.arange(45,85+1,10)])\n",
    "        )\n",
    "        \n",
    "        hospPos_data = df\n",
    "        \n",
    "        \n",
    "    # Join the two dataframes to align in time\n",
    "    df_full = joinDataAndSimCurves(\n",
    "        df_curves = hospPos_data, # a pandas dataframe with dates as index, and each column is a curve\n",
    "        simCurves = hospPos_Sim, # curves x time np array\n",
    "        simStartDate = simStartDate, # curves start dates\n",
    "        fulljoin = fulljoin\n",
    "    )\n",
    "    \n",
    "    # If true, outputs the data-curves and simulated curves instead of likelihood, for plotting\n",
    "    if outputDataframe:\n",
    "        return df_full\n",
    "    \n",
    "    \n",
    "    # We assume the order of columns in data and in simCurves are the same!\n",
    "    #return df_full\n",
    "    return np.nansum(\n",
    "        NegBinom_logpmf(2., \n",
    "                        # Select all simCurve columns and reshape to a single vector\n",
    "                        m = 1e-8+np.reshape(df_full.loc[:,df_full.columns.str.startswith(\"simCurve_\")==True].values,-1), \n",
    "                        # Select all data columns and reshape to a single vector\n",
    "                        x = np.reshape(df_full.loc[:,(df_full.columns.str.startswith(\"simCurve_\")==True)==False].values,-1)\n",
    "                       )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likFunc_newHospPositive(\n",
    "    sim = simExample_newOnly, \n",
    "    simStartDate = '2020-02-22',\n",
    "    df = copy.deepcopy(\n",
    "        df_CHESS_newCOVID\n",
    "    ),\n",
    "    sumAges=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the likelihoods\n",
    "def getLikelihoodsWithStartDates(\n",
    "    sims,\n",
    "    likFuncs,\n",
    "    simIndices,\n",
    "    dataTables,\n",
    "    startDates\n",
    "    ):\n",
    "    \n",
    "    out = np.zeros((len(likFuncs), len(startDates)))\n",
    "    \n",
    "    for ind, likFunc in enumerate(likFuncs):\n",
    "        out[ind] = np.array([\n",
    "            likFunc(\n",
    "                sim = sims[simIndices[ind]], \n",
    "                simStartDate = cur_startDate,\n",
    "                df = copy.deepcopy(dataTables[ind])\n",
    "            )\n",
    "            for cur_startDate in startDates\n",
    "        ])\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel execution with dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"127.0.0.1:8786\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up where to save and save default parameters\n",
    "\n",
    "timeOfRunning = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "\n",
    "saveDir = \"/mnt/efs/results/run_\" + timeOfRunning + \"/\"\n",
    "os.makedirs(saveDir, exist_ok=True)\n",
    "os.chmod(saveDir, 0o777) # enable workers to write the files\n",
    "\n",
    "# Save the default parameter dictionary that we'll merge with new inputs\n",
    "paramDict_default = build_paramDict(dydt_Complete)\n",
    "paramDict_default[\"dydt_Complete\"] = dydt_Complete\n",
    "paramDict_default[\"INIT_stateTensor_init\"] = stateTensor_init\n",
    "with open(saveDir+'paramDict_default.cpkl', 'wb') as fh:\n",
    "    cloudpickle.dump(paramDict_default, fh)\n",
    "    \n",
    "with open(saveDir+'ensembleParamPriors.cpkl', 'wb') as fh:\n",
    "    cloudpickle.dump(ensembleParamPriors, fh)\n",
    "\n",
    "with open(saveDir+'getGPR_prediction_func.cpkl', 'wb') as fh:\n",
    "    cloudpickle.dump(getGPR_prediction, fh)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run until infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parallel for each parameter setting and save to out_fname\n",
    "def runAll(newParams_row, stateTensor_init=stateTensor_init, defaultDict=paramDict_default, timeOfRunning=timeOfRunning):\n",
    "    # Run model \n",
    "    # Make sure the newOnly stuff is saved as well\n",
    "    curDict = copy.deepcopy(defaultDict)\n",
    "    curDict[\"debugReturnNewPerDay\"] = True\n",
    "    \n",
    "    out = solveSystem(stateTensor_init, \n",
    "                total_days = 80, # 80 days is enough to incorporate all data!\n",
    "                **paramTable_toDict(\n",
    "                            # keep only relevant columns in newParams_row for this\n",
    "                           newParams_row[list(set(newParams_row.columns) & set(paramDict_toTable(defaultDict).columns))].reset_index(drop=True),\n",
    "                           defaultDict=copy.deepcopy(curDict)\n",
    "                    )\n",
    "               )\n",
    "    # The out is now both the states and the cumsum\n",
    "    out_newOnly = np.diff(np.concatenate([np.expand_dims(copy.deepcopy(out[0][:,:,:,:,0]),axis=4), copy.deepcopy(out[1])], axis=-1), axis=-1)\n",
    "    out = out[0]\n",
    "    \n",
    "    \n",
    "    # Compute likelihoods\n",
    "    out_liks = getLikelihoodsWithStartDates(\n",
    "        sims= [out, out_newOnly], \n",
    "        likFuncs = [\n",
    "            lambda sim, simStartDate, df: likFunc_deaths( sim, simStartDate, df, sumAges=True),\n",
    "            lambda sim, simStartDate, df: likFunc_deaths( sim, simStartDate, df, sumAges=False),\n",
    "            lambda sim, simStartDate, df: likFunc_newHospPositive( sim, simStartDate, df, sumAges=True),\n",
    "            lambda sim, simStartDate, df: likFunc_newHospPositive( sim, simStartDate, df, sumAges=False)\n",
    "        ],\n",
    "        simIndices = [\n",
    "            1, 1, 1, 1\n",
    "        ],\n",
    "        dataTables = [\n",
    "            df_UK_NHS_daily_COVID_deaths,\n",
    "            df_UK_NHS_daily_COVID_deaths,\n",
    "            df_CHESS_newCOVID,\n",
    "            df_CHESS_newCOVID\n",
    "        ],\n",
    "        startDates = newParams_row['realStartDate']\n",
    "    )\n",
    "    \n",
    "    for i in range(out_liks.shape[0]):\n",
    "        newParams_row[\"likelihood_\" + str(i)] = out_liks[i,0]\n",
    "        \n",
    "    newParams_row[\"likelihood_total\"] = np.sum(out_liks)\n",
    "    \n",
    "    newParams_row[\"out_fname\"] = \"outTensor_\" + timeOfRunning + \"_\" + ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(20))+\".npy\"\n",
    "    \n",
    "    \n",
    "    return out, out_newOnly, newParams_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns numSelected parameter sets that we wish to evaluate, plus the remaining ones\n",
    "def gpSelectionFunction(proposedNewParams, numSelected, total_lik_threshold = -5000):\n",
    "    # Select not terrible ones, not necassirily best ones\n",
    "    ind_GoodCandidates = list(proposedNewParams.index[proposedNewParams.GPR_pred_mean_likelihood_total > total_lik_threshold])\n",
    "    if len(ind_GoodCandidates) > numSelected:\n",
    "        ind_GoodCandidates = random.sample(ind_GoodCandidates, numSelected)\n",
    "    \n",
    "    return (\n",
    "        # Good candidates\n",
    "        proposedNewParams.loc[ind_GoodCandidates],\n",
    "        # Remaining\n",
    "        proposedNewParams.loc[list(set(proposedNewParams.index)-set(ind_GoodCandidates))],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpNewProposalIter = 192\n",
    "gpNewProposalJobs = 100\n",
    "gpSOD = 180\n",
    "gpNewProposalMinibatchSize = 100\n",
    "maxTotalEnsemble = 200000\n",
    "\n",
    "\n",
    "curIndex = 0\n",
    "\n",
    "cur_gp_ind = 0\n",
    "cur_gp_batch = 0\n",
    "seqs_added = 0\n",
    "\n",
    "gp_futures = [] \n",
    "\n",
    "# # Submit an initial bunch of futures to serve as anchor points for GP regression\n",
    "futures = []\n",
    "for index in range(gpNewProposalIter+1):\n",
    "    tmp_params_row = getEnsembleParamSample(ensembleParamPriors=ensembleParamPriors)\n",
    "    fut = client.submit(runAll, tmp_params_row)\n",
    "    futures.append(fut)\n",
    "\n",
    "\n",
    "seq = as_completed(futures)\n",
    "    \n",
    "# Do the processing, and keep submitting new jobs on the fly\n",
    "for future in seq:\n",
    "    if future.status == \"finished\":\n",
    "        out, out_newOnly, newParams_row = future.result()\n",
    "            \n",
    "        # Save all the files\n",
    "        np.save(file = saveDir + newParams_row.at[0, \"out_fname\"],\n",
    "                        arr= out\n",
    "                    )\n",
    "\n",
    "        np.save(file = saveDir + newParams_row.at[0, \"out_fname\"][:-4]+\"_newOnly.npy\",\n",
    "                        arr= out_newOnly\n",
    "                    )\n",
    "        \n",
    "        newParams_row.index = [curIndex]\n",
    "        \n",
    "        if curIndex == 0:\n",
    "            paramTable_new = newParams_row\n",
    "            \n",
    "        else:\n",
    "            paramTable_new = paramTable_new.append(newParams_row)\n",
    "            \n",
    "        curIndex += 1\n",
    "        \n",
    "        if (curIndex % 100)==0:\n",
    "            # Save paramTable\n",
    "            paramTable_new.to_hdf(saveDir + \"paramTable_part{}\".format(0), key=\"paramTable\")\n",
    "        \n",
    "        # If no GP job is running, and we dont have a huge backlog submit some\n",
    "        if (not gp_futures) and (curIndex > gpNewProposalIter*0.8*(cur_gp_batch+1)) and (seqs_added-curIndex<2000):\n",
    "            cur_gp_batch += 1\n",
    "\n",
    "            # Submit some GP jobs\n",
    "            \n",
    "            # Calculate the current inverse\n",
    "            if curIndex == gpNewProposalIter: # very first time we do it blocking\n",
    "                paramTable_new, Ksor_inv = getGPR_prediction(paramTable_new, paramTable_new)\n",
    "            else:\n",
    "                # Compute it on a random subset, this should block only for few seconds\n",
    "                # Take best 100 + random rest\n",
    "                curSOD_inds = (\n",
    "                    list(paramTable_new.sort_values(\"likelihood_total\").tail(100).index) + \n",
    "                    random.sample(list(paramTable_new.index), gpSOD-100)\n",
    "                )\n",
    "                Ksor_inv_SOD = getGPR_prediction(\n",
    "                    copy.deepcopy(paramTable_new.loc[curSOD_inds]), \n",
    "                    copy.deepcopy(paramTable_new.loc[curSOD_inds]),\n",
    "                    return_Ksor_only=True\n",
    "                )\n",
    "                \n",
    "                # If we use Subset of Regressions instead of subset of Data, compute the projections as well!\n",
    "                # paramTable_new.loc[list(set(paramTable_new.index)-set(curSOR_inds))]\n",
    "\n",
    "            # Submit the GP jobs (this takes a while, would be good to have some more jobs before)\n",
    "            for i_gp in range(gpNewProposalJobs):\n",
    "                fut = client.submit(getGPR_prediction, \n",
    "                              copy.deepcopy(paramTable_new.loc[curSOD_inds]), \n",
    "                              getEnsembleParamSample(gpNewProposalMinibatchSize, ensembleParamPriors=ensembleParamPriors), \n",
    "                              Ksor_inv=Ksor_inv_SOD)\n",
    "                gp_futures.append(fut)\n",
    "                \n",
    "                \n",
    "        # Check every time if all GP jobs finished, but otherwise don't wait for them!\n",
    "        if gp_futures and all([gp_fut.status == \"finished\" for gp_fut in gp_futures]):\n",
    "                \n",
    "            # This is a blocking step to get new proposals\n",
    "            for gp_future in as_completed(gp_futures):\n",
    "                if gp_future.status == \"finished\":\n",
    "                    outNewParams = gp_future.result()\n",
    "\n",
    "                    if cur_gp_ind == 0:\n",
    "                        proposedNewParams = outNewParams\n",
    "                    else:\n",
    "                        proposedNewParams = proposedNewParams.append(outNewParams)\n",
    "                        \n",
    "                    cur_gp_ind+=1\n",
    "\n",
    "                client.cancel(gp_future)\n",
    "            \n",
    "            gp_futures = []\n",
    "                \n",
    "            proposedNewParams = proposedNewParams.reset_index(drop=True)\n",
    "            \n",
    "            if len(proposedNewParams)>100000:\n",
    "                proposedNewParams = proposedNewParams.loc[0:100000]\n",
    "                \n",
    "            # Submit new jobs based on the proposed params, keep the rest for use later\n",
    "            submitNewParams, proposedNewParams = gpSelectionFunction(\n",
    "                proposedNewParams, \n",
    "                numSelected=gpNewProposalIter,\n",
    "                total_lik_threshold=np.quantile(paramTable_new.loc[:,\"likelihood_total\"],0.75)\n",
    "            )\n",
    "            \n",
    "            print(\"Submitting {}/{} new jobs based on GP results\".format(len(submitNewParams), gpNewProposalIter))\n",
    "            \n",
    "            submitNewParams = submitNewParams.reset_index(drop=True)\n",
    "            for i in range(len(submitNewParams)):\n",
    "                tmp = copy.deepcopy(submitNewParams.loc[i:i])\n",
    "                tmp = tmp.reset_index(drop=True)\n",
    "                new_future = client.submit(runAll, tmp)\n",
    "                seq.add(new_future)\n",
    "                seqs_added += 1\n",
    "\n",
    "    client.cancel(future)\n",
    "    \n",
    "    # Check if we're running out of jobs, add some random ones\n",
    "    if curIndex - seqs_added > 50:\n",
    "        print(\"adding random jobs while waiting for GP to propose new ones...\")\n",
    "        for i11 in range(30):\n",
    "            tmp_params_row = getEnsembleParamSample(ensembleParamPriors=ensembleParamPriors)\n",
    "            new_future = client.submit(runAll, tmp_params_row)\n",
    "            seq.add(new_future)\n",
    "            seqs_added += 1\n",
    "            \n",
    "    if curIndex > maxTotalEnsemble:\n",
    "        client.cancel(futures)\n",
    "        client.cancel(gp_futures)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.cancel(gp_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py-corona-2-ensemble]",
   "language": "python",
   "name": "conda-env-.conda-py-corona-2-ensemble-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
